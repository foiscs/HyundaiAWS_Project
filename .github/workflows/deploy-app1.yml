# .github/workflows/deploy-app1.yml
# PHP ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ì›Œí¬í”Œë¡œìš° (server1 í´ë” ë³€ê²½ì‹œë§Œ ì‹¤í–‰)

name: Deploy PHP Application 1

on:
  push:
    branches: [ main ]
    paths:
      - 'WALB/server1/**'
      - '.github/workflows/deploy-app1.yml'
  
jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    # ì›Œí‚¹ ë””ë ‰í† ë¦¬ë¥¼ WALBë¡œ ì„¤ì •
    defaults:
      run:
        working-directory: ./WALB
    
    permissions:
      id-token: write
      contents: read
    
    steps:
    # ===============================================
    # ì†ŒìŠ¤ì½”ë“œ ì²´í¬ì•„ì›ƒ
    # ===============================================
    - name: Checkout code
      uses: actions/checkout@v4
    
    # ===============================================
    # app1-config.ymlì—ì„œ ì„¤ì •ê°’ ë¡œë“œ
    # ===============================================
    - name: Load config from app1-config.yml
      run: |
        echo "ğŸ“‹ app1-config.ymlì—ì„œ ì„¤ì •ê°’ ë¡œë“œ ì¤‘..."
        
        # yq ì„¤ì¹˜
        sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
        sudo chmod +x /usr/local/bin/yq
        
        # app1-config.ymlì—ì„œ ê°’ ì½ê¸°
        PROJECT_NAME=$(yq eval '.app1_config.project_name' ../.github/workflows/config/app1-config.yml)
        DB_NAME=$(yq eval '.app1_config.database.name' ../.github/workflows/config/app1-config.yml)
        DB_USER=$(yq eval '.app1_config.database.user' ../.github/workflows/config/app1-config.yml)
        DB_PORT=$(yq eval '.app1_config.database.port' ../.github/workflows/config/app1-config.yml)
        DB_RDS_IDENTIFIER=$(yq eval '.app1_config.database.rds_identifier' ../.github/workflows/config/app1-config.yml)
        EKS_CLUSTER_NAME=$(yq eval '.app1_config.eks.cluster_name' ../.github/workflows/config/app1-config.yml)
        S3_BUCKET_NAME=$(yq eval '.app1_config.s3.bucket_name' ../.github/workflows/config/app1-config.yml)
        IAM_ROLE_NAME=$(yq eval '.app1_config.iam.role_name' ../.github/workflows/config/app1-config.yml)
        BASTION_HOST_TAG=$(yq eval '.app1_config.bastion.host_tag_name' ../.github/workflows/config/app1-config.yml)
        DEPLOYMENT_NAME=$(yq eval '.app1_config.application.deployment_name' ../.github/workflows/config/app1-config.yml)
        IMAGE_NAME=$(yq eval '.app1_config.application.image_name' ../.github/workflows/config/app1-config.yml)
        HEALTH_CHECK_PATH=$(yq eval '.app1_config.application.health_check_path' ../.github/workflows/config/app1-config.yml)
        AWS_REGION=$(yq eval '.app1_config.network.region' ../.github/workflows/config/app1-config.yml)
        
        # í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •
        echo "PROJECT_NAME=$PROJECT_NAME" >> $GITHUB_ENV
        echo "DB_NAME=$DB_NAME" >> $GITHUB_ENV
        echo "DB_USER=$DB_USER" >> $GITHUB_ENV
        echo "DB_PORT=$DB_PORT" >> $GITHUB_ENV
        echo "DB_RDS_IDENTIFIER=$DB_RDS_IDENTIFIER" >> $GITHUB_ENV
        echo "EKS_CLUSTER_NAME=$EKS_CLUSTER_NAME" >> $GITHUB_ENV
        echo "S3_BUCKET_NAME=$S3_BUCKET_NAME" >> $GITHUB_ENV
        echo "IAM_ROLE_NAME=$IAM_ROLE_NAME" >> $GITHUB_ENV
        echo "BASTION_HOST_TAG=$BASTION_HOST_TAG" >> $GITHUB_ENV
        echo "DEPLOYMENT_NAME=$DEPLOYMENT_NAME" >> $GITHUB_ENV
        echo "IMAGE_NAME=$IMAGE_NAME" >> $GITHUB_ENV
        echo "HEALTH_CHECK_PATH=$HEALTH_CHECK_PATH" >> $GITHUB_ENV
        echo "AWS_REGION=$AWS_REGION" >> $GITHUB_ENV
        
        echo "âœ… ì„¤ì •ê°’ ë¡œë“œ ì™„ë£Œ"
        echo "PROJECT_NAME: $PROJECT_NAME"
        echo "DB_NAME: $DB_NAME"
        echo "AWS_REGION: $AWS_REGION"
    
    # ===============================================
    # PHP ë° Composer í™˜ê²½ ì„¤ì •
    # ===============================================
    - name: Set up PHP
      uses: shivammathur/setup-php@v2
      with:
        php-version: '8.1'
        extensions: pdo, pdo_pgsql, mbstring, xml, zip, gd
        coverage: none
    
    - name: Validate Composer
      run: |
        echo "ğŸ” PHP ì• í”Œë¦¬ì¼€ì´ì…˜ ê²€ì¦ ì¤‘.."
        if [ -f "server1/composer.json" ]; then
          cd server1
          composer validate --no-check-publish
          composer install --no-dev --optimize-autoloader --no-interaction
          echo "âœ… Composer ê²€ì¦ ì™„ë£Œ"
        else
          echo "â„¹ï¸ Composer íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Docker ë¹Œë“œë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤"
        fi
    
    # ===============================================
    # AWS ì¸ì¦ (OIDC ë°©ì‹)
    # ===============================================
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_ARN_APP1 }}
        aws-region: ${{ secrets.AWS_REGION }}
        role-session-name: GitHubActions-Application-${{ github.run_id }}

    # ===============================================
    # ê¸°ì¡´ ì¸í”„ë¼ ì •ë³´ ì¡°íšŒ
    # ===============================================
    - name: Get Infrastructure Resources
      run: |
        echo "ğŸ” ê¸°ì¡´ ì¸í”„ë¼ ë¦¬ì†ŒìŠ¤ ì •ë³´ ì¡°íšŒ ì¤‘..."
        
        # ECR ë¦¬í¬ì§€í† ë¦¬ URI ì¡°íšŒ
        ECR_REPO=$(aws ecr describe-repositories --repository-names ${PROJECT_NAME}-ecr --query 'repositories[0].repositoryUri' --output text 2>/dev/null || echo "")
        if [ -z "$ECR_REPO" ]; then
          echo "âŒ ECR ë¦¬í¬ì§€í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${PROJECT_NAME}-ecr"
          echo "ë¨¼ì € ì¸í”„ë¼ ë°°í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
          exit 1
        fi
        echo "ECR_REPOSITORY=$ECR_REPO" >> $GITHUB_ENV
        echo "âœ… ECR Repository: $ECR_REPO"
        
        # EKS í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì¡°íšŒ  
        EKS_CLUSTER=$(aws eks describe-cluster --name $EKS_CLUSTER_NAME --query 'cluster.name' --output text 2>/dev/null || echo "")
        if [ -z "$EKS_CLUSTER" ] || [ "$EKS_CLUSTER" == "None" ]; then
          echo "âŒ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${PROJECT_NAME}-eks"
          echo "ë¨¼ì € ì¸í”„ë¼ ë°°í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
          exit 1
        fi
        echo "EKS_CLUSTER_NAME=$EKS_CLUSTER" >> $GITHUB_ENV
        echo "âœ… EKS Cluster: $EKS_CLUSTER"
        
        # RDS ì—”ë“œí¬ì¸íŠ¸ ì¡°íšŒ
        RDS_ENDPOINT=$(aws rds describe-db-instances --db-instance-identifier $DB_RDS_IDENTIFIER --query 'DBInstances[0].Endpoint.Address' --output text 2>/dev/null || echo "")
        if [ -z "$RDS_ENDPOINT" ] || [ "$RDS_ENDPOINT" == "None" ]; then
          echo "âŒ RDS ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
          echo "ë¨¼ì € ì¸í”„ë¼ ë°°í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
          exit 1
        fi
        echo "RDS_ENDPOINT=$RDS_ENDPOINT" >> $GITHUB_ENV
        echo "âœ… RDS Endpoint: $RDS_ENDPOINT"
        
        # EKS í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
        EKS_STATUS=$(aws eks describe-cluster --name $EKS_CLUSTER --query 'cluster.status' --output text)
        if [ "$EKS_STATUS" != "ACTIVE" ]; then
          echo "âŒ EKS í´ëŸ¬ìŠ¤í„°ê°€ í™œì„± ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤: $EKS_STATUS"
          exit 1
        fi
        echo "âœ… EKS Cluster Status: $EKS_STATUS"

    # ===============================================
    # EKS ë³´ì•ˆê·¸ë£¹ ê·œì¹™ í™•ì¸ ë° ìë™ ìˆ˜ì • (kubelet í†µì‹ ìš©)
    # ===============================================
    - name: Check and fix EKS security group rules
      run: |
        echo "ğŸ” EKS ë³´ì•ˆê·¸ë£¹ 10250 í¬íŠ¸ ê·œì¹™ í™•ì¸ ì¤‘..."
        
        # ì›Œì»¤ë…¸ë“œ ë³´ì•ˆê·¸ë£¹ ID ì¡°íšŒ
        NODE_SG_ID=$(aws ec2 describe-instances \
          --filters "Name=tag:kubernetes.io/cluster/$EKS_CLUSTER_NAME,Values=owned" \
          --query "Reservations[*].Instances[*].SecurityGroups[*].GroupId" \
          --output text | tr '\t' '\n' | sort | uniq | head -1)
        
        # í´ëŸ¬ìŠ¤í„° ë³´ì•ˆê·¸ë£¹ ID ì¡°íšŒ  
        CLUSTER_SG_ID=$(aws eks describe-cluster --name $EKS_CLUSTER_NAME \
          --query "cluster.resourcesVpcConfig.securityGroupIds[0]" --output text)
        
        if [ -z "$NODE_SG_ID" ] || [ -z "$CLUSTER_SG_ID" ]; then
          echo "âš ï¸ ë³´ì•ˆê·¸ë£¹ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤."
          echo "NODE_SG_ID: $NODE_SG_ID"
          echo "CLUSTER_SG_ID: $CLUSTER_SG_ID"
        else
          echo "ğŸ“‹ ë³´ì•ˆê·¸ë£¹ ì •ë³´:"
          echo "  Worker Node SG: $NODE_SG_ID"
          echo "  Cluster SG: $CLUSTER_SG_ID"
          
          # 10250 í¬íŠ¸ ê·œì¹™ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
          RULE_EXISTS=$(aws ec2 describe-security-groups --group-ids $NODE_SG_ID \
            --query "SecurityGroups[0].GroupRules[?FromPort==\`10250\` && ToPort==\`10250\` && IsEgress==\`false\`]" \
            --output text)
          
          if [ -z "$RULE_EXISTS" ]; then
            echo "âš ï¸ kubelet í†µì‹ ìš© 10250 í¬íŠ¸ ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤. ì¶”ê°€ ì¤‘..."
            
            # 10250 í¬íŠ¸ ì¸ë°”ìš´ë“œ ê·œì¹™ ì¶”ê°€ (í´ëŸ¬ìŠ¤í„°ì—ì„œ ë…¸ë“œë¡œ)
            aws ec2 authorize-security-group-ingress \
              --group-id $NODE_SG_ID \
              --protocol tcp \
              --port 10250 \
              --source-group $CLUSTER_SG_ID \
              --description "Allow kubelet communication from control plane (auto-added by GitHub Actions)" \
              2>/dev/null && echo "âœ… 10250 í¬íŠ¸ ê·œì¹™ ì¶”ê°€ ì™„ë£Œ" || echo "âš ï¸ ê·œì¹™ ì¶”ê°€ ì‹¤íŒ¨ (ì´ë¯¸ ì¡´ì¬í•  ìˆ˜ ìˆìŒ)"
            
          else
            echo "âœ… kubelet í†µì‹ ìš© 10250 í¬íŠ¸ ê·œì¹™ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤"
          fi
        fi
    
    # ===============================================
    # ECR ë¡œê·¸ì¸
    # ===============================================
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
    
    # ===============================================
    # Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ
    # ===============================================
    - name: Build and push Docker image
      id: build-image
      run: |
        echo "ğŸ³ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."
        
        # Git ì»¤ë°‹ í•´ì‹œë¥¼ íƒœê·¸ë¡œ ì‚¬ìš©
        IMAGE_TAG=${{ github.sha }}
        IMAGE_URI=${{ env.ECR_REPOSITORY }}:$IMAGE_TAG
        
        # server1 í´ë”ë¡œ ì´ë™í•´ì„œ Docker ë¹Œë“œ
        cd server1
        docker build -t $IMAGE_URI .
        docker tag $IMAGE_URI ${{ env.ECR_REPOSITORY }}:latest
        
        echo "ğŸ“¤ ECRì— ì´ë¯¸ì§€ í‘¸ì‹œ ì¤‘..."
        docker push $IMAGE_URI
        docker push ${{ env.ECR_REPOSITORY }}:latest
        
        echo "âœ… ì´ë¯¸ì§€ í‘¸ì‹œ ì™„ë£Œ: $IMAGE_URI"
        echo "image=$IMAGE_URI" >> $GITHUB_OUTPUT

    - name: Test Database Connection via Bastion
      run: |
        # AWS CLIë¥¼ ì‚¬ìš©í•´ì„œ ë¦¬ì†ŒìŠ¤ ì •ë³´ ì§ì ‘ ì¡°íšŒ
        PROJECT_NAME="${{ env.PROJECT_NAME }}"
        
        echo "ğŸ” ì„¤ì •ëœ í™˜ê²½ë³€ìˆ˜:"
        echo "  PROJECT_NAME: $PROJECT_NAME"
        
        # RDS ì—”ë“œí¬ì¸íŠ¸ ì¡°íšŒ (walb-app í”„ë¡œì íŠ¸ìš©)
        echo "ğŸ” RDS ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì¤‘..."
        DB_HOST=$(aws rds describe-db-instances \
          --db-instance-identifier $DB_RDS_IDENTIFIER \
          --query "DBInstances[0].Endpoint.Address" \
          --output text 2>/dev/null || echo "")
        
        if [ -z "$DB_HOST" ] || [ "$DB_HOST" == "None" ]; then
          # ì§ì ‘ ì‹ë³„ìë¡œ ì•ˆ ë˜ë©´ íƒœê·¸ ê¸°ë°˜ìœ¼ë¡œ ì¡°íšŒ
          DB_HOST=$(aws rds describe-db-instances \
            --query "DBInstances[?contains(keys(TagList[?Key=='Project']), 'Project') && TagList[?Key=='Project'].Value[0]=='${PROJECT_NAME}'].Endpoint.Address" \
            --output text 2>/dev/null || echo "")
        fi
        
        # Bastion Host IP ì¡°íšŒ (ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„)
        echo "ğŸ” Bastion Host ì¡°íšŒ ì¤‘..."
        
        # ë°©ë²• 1: ì •í™•í•œ íƒœê·¸ ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ
        BASTION_IP=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=${PROJECT_NAME}-bastion-host" "Name=instance-state-name,Values=running" \
          --query "Reservations[0].Instances[0].PublicIpAddress" \
          --output text 2>/dev/null || echo "")
        
        if [ -z "$BASTION_IP" ] || [ "$BASTION_IP" == "None" ]; then
          echo "âš ï¸ ë°©ë²• 1 ì‹¤íŒ¨. ëŒ€ì²´ ë°©ë²• ì‹œë„ ì¤‘..."
          
          # ë°©ë²• 2: Component íƒœê·¸ë¡œ ì¡°íšŒ
          BASTION_IP=$(aws ec2 describe-instances \
            --filters "Name=tag:Component,Values=Bastion" "Name=instance-state-name,Values=running" "Name=tag:Project,Values=${PROJECT_NAME}" \
            --query "Reservations[0].Instances[0].PublicIpAddress" \
            --output text 2>/dev/null || echo "")
        fi
        
        if [ -z "$BASTION_IP" ] || [ "$BASTION_IP" == "None" ]; then
          echo "âŒ Bastion Hostë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          echo "ğŸ” ë””ë²„ê¹… ì •ë³´:"
          echo "  ì°¾ê³  ìˆëŠ” íƒœê·¸: Name=${PROJECT_NAME}-bastion-host"
          echo "  ë˜ëŠ” Component=Bastion, Project=${PROJECT_NAME}"
          
          echo "ğŸ” í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì¸ìŠ¤í„´ìŠ¤ë“¤:"
          aws ec2 describe-instances \
            --filters "Name=instance-state-name,Values=running" \
            --query "Reservations[*].Instances[*].[InstanceId,Tags[?Key=='Name'].Value[0] | [0],Tags[?Key=='Component'].Value[0] | [0],Tags[?Key=='Project'].Value[0] | [0],PublicIpAddress]" \
            --output table || echo "ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨"
          
          exit 1
        fi
        
        # DB ì‚¬ìš©ìëª…ê³¼ DB ì´ë¦„ (í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©)
        DB_NAME="mydb"
        DB_USER="dbadmin"
        
        # Parameter Storeì—ì„œ DB íŒ¨ìŠ¤ì›Œë“œ ì¡°íšŒ
        echo "ğŸ” DB íŒ¨ìŠ¤ì›Œë“œ ì¡°íšŒ ì¤‘..."
        DB_PASSWORD=$(aws ssm get-parameter \
          --name "/${PROJECT_NAME}/rds/master-password" \
          --with-decryption \
          --query 'Parameter.Value' \
          --output text 2>/dev/null || echo "")
        
        # ê°’ ê²€ì¦
        if [ -z "$DB_HOST" ] || [ "$DB_HOST" == "None" ]; then
          echo "âŒ RDS ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          echo "ì‚¬ìš© ê°€ëŠ¥í•œ RDS ì¸ìŠ¤í„´ìŠ¤:"
          aws rds describe-db-instances --query "DBInstances[*].[DBInstanceIdentifier,Endpoint.Address,DBName]" --output table
          exit 1
        fi
        
        if [ -z "$BASTION_IP" ] || [ "$BASTION_IP" == "None" ]; then
          echo "âŒ Bastion Hostë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          echo "ì‹¤í–‰ ì¤‘ì¸ EC2 ì¸ìŠ¤í„´ìŠ¤:"
          aws ec2 describe-instances \
            --filters "Name=instance-state-name,Values=running" \
            --query "Reservations[*].Instances[*].[InstanceId,PublicIpAddress,Tags[?Key=='Name'].Value[0]]" \
            --output table
          exit 1
        fi
        
        if [ -z "$DB_PASSWORD" ]; then
          echo "âŒ DB íŒ¨ìŠ¤ì›Œë“œë¥¼ Parameter Storeì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          exit 1
        fi
        
        echo "âœ… DB Host: '$DB_HOST'"
        echo "âœ… Bastion IP: '$BASTION_IP'"
        echo "âœ… DB User: '$DB_USER'"
        echo "âœ… DB Name: '$DB_NAME'"
        
        # SSH í‚¤ë¥¼ Parameter Storeì—ì„œ ê°€ì ¸ì˜¤ê¸°
        echo "ğŸ”‘ SSH í‚¤ ì¡°íšŒ ì¤‘..."
        aws ssm get-parameter \
          --name "/${PROJECT_NAME}/bastion/ssh-private-key" \
          --with-decryption \
          --query 'Parameter.Value' \
          --output text > bastion_key.pem
        chmod 600 bastion_key.pem
        
        echo "ğŸ” SSH ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
        # SSH ì—°ê²° í…ŒìŠ¤íŠ¸ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
        if ! ssh -i bastion_key.pem -o StrictHostKeyChecking=no -o ConnectTimeout=10 -o BatchMode=yes ec2-user@$BASTION_IP "echo 'SSH connection successful'" 2>/dev/null; then
          echo "âŒ SSH ì—°ê²° ì‹¤íŒ¨. Bastion Host ìƒíƒœ í™•ì¸:"
          aws ec2 describe-instances \
            --filters "Name=tag:Component,Values=Bastion" \
            --query "Reservations[*].Instances[*].[InstanceId,State.Name,PublicIpAddress,PrivateIpAddress]" \
            --output table
          exit 1
        fi
        
        echo "ğŸ”— SSH í„°ë„ì„ í†µí•œ PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
        
        # PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ (ë¨¼ì € ì„¤ì¹˜)
        if ! command -v psql &> /dev/null; then
          echo "ğŸ“¦ PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ ì¤‘..."
          sudo apt-get update -qq && sudo apt-get install -y postgresql-client
        fi
        
        # ë¡œì»¬ í¬íŠ¸ê°€ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸
        if netstat -tuln | grep -q ":${{ env.DB_PORT }} "; then
          echo "âš ï¸ í¬íŠ¸ ${{ env.DB_PORT }}ì´ ì´ë¯¸ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. ë‹¤ë¥¸ í¬íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
          LOCAL_PORT=$((${{ env.DB_PORT }} + 1))
        else
          LOCAL_PORT=${{ env.DB_PORT }}
        fi
        
        # DB_HOSTì—ì„œ ì™€ì¼ë“œì¹´ë“œ ì œê±° (ë³´ì•ˆìƒ ë§ˆìŠ¤í‚¹ëœ ë¶€ë¶„ ì²˜ë¦¬)
        DB_HOST_CLEAN=$(echo "$DB_HOST" | sed 's/\*\*\*[^.]*//g' | sed 's/\.\././g')
        if [[ "$DB_HOST_CLEAN" != "$DB_HOST" ]]; then
          echo "âš ï¸ DB_HOSTì— ë§ˆìŠ¤í‚¹ëœ ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì—”ë“œí¬ì¸íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤."
          DB_HOST="$RDS_ENDPOINT"
        fi
        
        echo "ğŸ” ì‚¬ìš©í•  DB ì—”ë“œí¬ì¸íŠ¸: $DB_HOST"
        
        echo "ğŸ”— SSH í„°ë„ ìƒì„± ì¤‘... (ë¡œì»¬ í¬íŠ¸: $LOCAL_PORT)"
        # SSH í„°ë„ ìƒì„± with ë” ë§ì€ ì˜µì…˜
        ssh -i bastion_key.pem \
            -o StrictHostKeyChecking=no \
            -o UserKnownHostsFile=/dev/null \
            -o ExitOnForwardFailure=yes \
            -o ServerAliveInterval=60 \
            -o ServerAliveCountMax=3 \
            -o ConnectTimeout=30 \
            -L $LOCAL_PORT:$DB_HOST:5432 \
            ec2-user@$BASTION_IP \
            -N &
        SSH_PID=$!
        
        # SSH í„°ë„ì´ ì •ìƒì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
        echo "â³ SSH í„°ë„ ì„¤ì • í™•ì¸ ì¤‘..."
        sleep 5
        
        # SSH í”„ë¡œì„¸ìŠ¤ê°€ ì•„ì§ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
        if ! kill -0 $SSH_PID 2>/dev/null; then
          echo "âŒ SSH í„°ë„ ìƒì„± ì‹¤íŒ¨"
          echo "SSH ì—°ê²° ë¡œê·¸ í™•ì¸:"
          ssh -i bastion_key.pem -o StrictHostKeyChecking=no ec2-user@$BASTION_IP "echo 'SSH ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ'" || echo "SSH ê¸°ë³¸ ì—°ê²° ì‹¤íŒ¨"
          rm -f bastion_key.pem
          exit 1
        fi
        
        # í„°ë„ í¬íŠ¸ê°€ ì—´ë ¸ëŠ”ì§€ í™•ì¸
        echo "ğŸ” í„°ë„ í¬íŠ¸ í™•ì¸ ì¤‘..."
        for i in {1..30}; do
          if netstat -tuln | grep -q ":$LOCAL_PORT "; then
            echo "âœ… SSH í„°ë„ì´ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤ (í¬íŠ¸: $LOCAL_PORT)"
            break
          fi
          if [ $i -eq 30 ]; then
            echo "âŒ SSH í„°ë„ í¬íŠ¸ ì„¤ì • ì‹œê°„ ì´ˆê³¼"
            kill $SSH_PID 2>/dev/null
            rm -f bastion_key.pem
            exit 1
          fi
          sleep 2
        done
        
        # Bastion Hostì—ì„œ ì§ì ‘ DB ì—°ê²° í…ŒìŠ¤íŠ¸
        echo "ğŸ” Bastion Hostì—ì„œ DB ì§ì ‘ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
        ssh -i bastion_key.pem -o StrictHostKeyChecking=no ec2-user@$BASTION_IP "
          # PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ í™•ì¸
          if ! command -v psql &> /dev/null; then
            echo 'ğŸ“¦ Bastionì— PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ ì¤‘...'
            sudo yum update -y
            sudo yum install -y postgresql15
          fi
          
          # DB ì—°ê²° í…ŒìŠ¤íŠ¸
          echo 'ğŸ” Bastionì—ì„œ RDS ì§ì ‘ ì—°ê²° í…ŒìŠ¤íŠ¸...'
          if PGPASSWORD='$DB_PASSWORD' psql -h $DB_HOST -p 5432 -U $DB_USER -d $DB_NAME -c 'SELECT version();' 2>/dev/null; then
            echo 'âœ… Bastionì—ì„œ RDS ì§ì ‘ ì—°ê²° ì„±ê³µ'
          else
            echo 'âŒ Bastionì—ì„œ RDS ì§ì ‘ ì—°ê²° ì‹¤íŒ¨'
            echo 'ğŸ” ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸:'
            telnet $DB_HOST 5432 < /dev/null 2>&1 | head -5
            echo 'ğŸ” ë³´ì•ˆ ê·¸ë£¹ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.'
            exit 1
          fi
        "
        
        # í„°ë„ì„ í†µí•œ ì—°ê²° í…ŒìŠ¤íŠ¸ (ì¬ì‹œë„ ë¡œì§ ì¶”ê°€)
        echo "ğŸ” SSH í„°ë„ì„ í†µí•œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
        DB_CONNECTED=false
        for i in {1..5}; do
          if PGPASSWORD=$DB_PASSWORD psql -h localhost -p $LOCAL_PORT -U $DB_USER -d $DB_NAME -c "SELECT 1;" 2>/dev/null; then
            echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ (ì‹œë„ $i/5)"
            DB_CONNECTED=true
            break
          else
            echo "âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ $i/5)"
            # ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ì¶œë ¥
            echo "ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:"
            PGPASSWORD=$DB_PASSWORD psql -h localhost -p $LOCAL_PORT -U $DB_USER -d $DB_NAME -c "SELECT 1;" 2>&1 || true
            
            if [ $i -lt 5 ]; then
              echo "3ì´ˆ í›„ ì¬ì‹œë„..."
              sleep 3
            fi
          fi
        done
        
        if [ "$DB_CONNECTED" != "true" ]; then
          echo "âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìµœì¢… ì‹¤íŒ¨"
          echo "ğŸ” ì—°ê²° ì •ë³´ í™•ì¸:"
          echo "  ë¡œì»¬ í¬íŠ¸: $LOCAL_PORT"
          echo "  DB í˜¸ìŠ¤íŠ¸: $DB_HOST"
          echo "  DB ì‚¬ìš©ì: $DB_USER"
          echo "  DB ì´ë¦„: $DB_NAME"
          echo "ğŸ” ë„¤íŠ¸ì›Œí¬ ìƒíƒœ:"
          netstat -tuln | grep ":$LOCAL_PORT"
          echo "ğŸ” SSH í„°ë„ ìƒíƒœ:"
          ps aux | grep ssh | grep $BASTION_IP || echo "SSH í”„ë¡œì„¸ìŠ¤ ì—†ìŒ"
          kill $SSH_PID 2>/dev/null
          rm -f bastion_key.pem
          exit 1
        fi
        
        # SSH í„°ë„ ì¢…ë£Œ ë° ì •ë¦¬
        echo "ğŸ§¹ SSH í„°ë„ ì •ë¦¬ ì¤‘..."
        kill $SSH_PID 2>/dev/null
        rm -f bastion_key.pem
        
        echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
      env:
        PROJECT_NAME: ${{ env.PROJECT_NAME }}
        
    # ===============================================
    # PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ ë° ìŠ¤í‚¤ë§ˆ ì ìš©
    # ===============================================
    - name: Apply Database Schema
      if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
      run: |
        echo "ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì ìš© ì¤‘..."
        
        # PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜
        sudo apt-get update && sudo apt-get install -y postgresql-client
        
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        PROJECT_NAME="${{ env.PROJECT_NAME }}"
        DB_HOST="${{ env.RDS_ENDPOINT }}"
        DB_NAME="mydb"
        DB_USER="dbadmin"
        
        echo "ğŸ” ì„¤ì •ëœ í™˜ê²½ë³€ìˆ˜:"
        echo "  PROJECT_NAME: $PROJECT_NAME"
        echo "  DB_HOST: $DB_HOST"
        
        # Bastion Host IP ì¡°íšŒ (ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„)
        echo "ğŸ” Bastion Host ì¡°íšŒ ì¤‘..."
        
        # ë°©ë²• 1: ì •í™•í•œ íƒœê·¸ ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ
        BASTION_IP=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=${PROJECT_NAME}-bastion-host" "Name=instance-state-name,Values=running" \
          --query "Reservations[0].Instances[0].PublicIpAddress" \
          --output text 2>/dev/null || echo "")
        
        if [ -z "$BASTION_IP" ] || [ "$BASTION_IP" == "None" ]; then
          echo "âš ï¸ ë°©ë²• 1 ì‹¤íŒ¨. ëŒ€ì²´ ë°©ë²• ì‹œë„ ì¤‘..."
          
          # ë°©ë²• 2: Component íƒœê·¸ë¡œ ì¡°íšŒ
          BASTION_IP=$(aws ec2 describe-instances \
            --filters "Name=tag:Component,Values=Bastion" "Name=instance-state-name,Values=running" "Name=tag:Project,Values=${PROJECT_NAME}" \
            --query "Reservations[0].Instances[0].PublicIpAddress" \
            --output text 2>/dev/null || echo "")
        fi
        
        if [ -z "$BASTION_IP" ] || [ "$BASTION_IP" == "None" ]; then
          echo "âŒ Bastion Hostë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          echo "ğŸ” ë””ë²„ê¹… ì •ë³´:"
          echo "  ì°¾ê³  ìˆëŠ” íƒœê·¸: Name=${PROJECT_NAME}-bastion-host"
          echo "  ë˜ëŠ” Component=Bastion, Project=${PROJECT_NAME}"
          
          echo "ğŸ” í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì¸ìŠ¤í„´ìŠ¤ë“¤:"
          aws ec2 describe-instances \
            --filters "Name=instance-state-name,Values=running" \
            --query "Reservations[*].Instances[*].[InstanceId,Tags[?Key=='Name'].Value[0] | [0],Tags[?Key=='Component'].Value[0] | [0],Tags[?Key=='Project'].Value[0] | [0],PublicIpAddress]" \
            --output table || echo "ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨"
          
          exit 1
        fi
        
        echo "ğŸ” ì—°ê²° ì •ë³´:"
        echo "  RDS ì—”ë“œí¬ì¸íŠ¸: $DB_HOST"
        echo "  Bastion IP: $BASTION_IP"
        echo "  DB ì´ë¦„: $DB_NAME"
        echo "  DB ì‚¬ìš©ì: $DB_USER"
        
        # SSH í‚¤ë¥¼ Parameter Storeì—ì„œ ê°€ì ¸ì˜¤ê¸°
        echo "ğŸ”‘ SSH í‚¤ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."
        aws ssm get-parameter \
          --name "/${PROJECT_NAME}/bastion/ssh-private-key" \
          --with-decryption \
          --query 'Parameter.Value' \
          --output text > bastion_key.pem
        chmod 600 bastion_key.pem
        
        # ë¡œì»¬ í¬íŠ¸ê°€ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸
        if netstat -tuln | grep -q ":${{ env.DB_PORT }} "; then
          echo "âš ï¸ í¬íŠ¸ ${{ env.DB_PORT }}ì´ ì´ë¯¸ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. ë‹¤ë¥¸ í¬íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
          LOCAL_PORT=$((${{ env.DB_PORT }} + 1))
        else
          LOCAL_PORT=${{ env.DB_PORT }}
        fi
        
        # SSH í„°ë„ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
        echo "ğŸ”— SSH í„°ë„ ìƒì„± ì¤‘... (ë¡œì»¬ í¬íŠ¸: $LOCAL_PORT)"
        ssh -i bastion_key.pem \
            -o StrictHostKeyChecking=no \
            -o UserKnownHostsFile=/dev/null \
            -o ExitOnForwardFailure=yes \
            -o ServerAliveInterval=60 \
            -o ServerAliveCountMax=3 \
            -o ConnectTimeout=30 \
            -L $LOCAL_PORT:$DB_HOST:5432 \
            ec2-user@$BASTION_IP \
            -N &
        SSH_PID=$!
        
        # í„°ë„ ì„¤ì • ëŒ€ê¸° ë° í™•ì¸
        echo "â³ SSH í„°ë„ ì„¤ì • í™•ì¸ ì¤‘..."
        sleep 5
        
        # SSH í„°ë„ ìƒíƒœ í™•ì¸
        if ! kill -0 $SSH_PID 2>/dev/null; then
          echo "âŒ SSH í„°ë„ ìƒì„± ì‹¤íŒ¨"
          echo "SSH ì—°ê²° ë¡œê·¸ í™•ì¸:"
          ssh -i bastion_key.pem -o StrictHostKeyChecking=no ec2-user@$BASTION_IP "echo 'SSH ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ'" || echo "SSH ê¸°ë³¸ ì—°ê²° ì‹¤íŒ¨"
          rm -f bastion_key.pem
          exit 1
        fi
        
        # í„°ë„ í¬íŠ¸ê°€ ì—´ë ¸ëŠ”ì§€ í™•ì¸
        echo "ğŸ” í„°ë„ í¬íŠ¸ í™•ì¸ ì¤‘..."
        for i in {1..30}; do
          if netstat -tuln | grep -q ":$LOCAL_PORT "; then
            echo "âœ… SSH í„°ë„ì´ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤ (í¬íŠ¸: $LOCAL_PORT)"
            break
          fi
          if [ $i -eq 30 ]; then
            echo "âŒ SSH í„°ë„ í¬íŠ¸ ì„¤ì • ì‹œê°„ ì´ˆê³¼"
            kill $SSH_PID 2>/dev/null
            rm -f bastion_key.pem
            exit 1
          fi
          sleep 2
        done
        
        echo "âœ… SSH í„°ë„ ìƒì„± ì™„ë£Œ"
        
        # Bastion Hostì—ì„œ ì§ì ‘ DB ì—°ê²° í…ŒìŠ¤íŠ¸
        echo "ğŸ” Bastion Hostì—ì„œ DB ì§ì ‘ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
        ssh -i bastion_key.pem -o StrictHostKeyChecking=no ec2-user@$BASTION_IP "
          # PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ í™•ì¸
          if ! command -v psql &> /dev/null; then
            echo 'ğŸ“¦ Bastionì— PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ ì¤‘...'
            sudo yum update -y
            sudo yum install -y postgresql15
          fi
          
          # DB ì—°ê²° í…ŒìŠ¤íŠ¸
          echo 'ğŸ” Bastionì—ì„œ RDS ì§ì ‘ ì—°ê²° í…ŒìŠ¤íŠ¸...'
          if PGPASSWORD='${{ secrets.DB_PASSWORD }}' psql -h $DB_HOST -p 5432 -U $DB_USER -d $DB_NAME -c 'SELECT version();' 2>/dev/null; then
            echo 'âœ… Bastionì—ì„œ RDS ì§ì ‘ ì—°ê²° ì„±ê³µ'
          else
            echo 'âŒ Bastionì—ì„œ RDS ì§ì ‘ ì—°ê²° ì‹¤íŒ¨'
            echo 'ğŸ” ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸:'
            nc -zv $DB_HOST 5432 2>&1 || telnet $DB_HOST 5432 < /dev/null 2>&1 | head -5
            echo 'ğŸ” ë³´ì•ˆ ê·¸ë£¹ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.'
            exit 1
          fi
        "
        
        # ë¡œì»¬ í¬íŠ¸ë¥¼ í†µí•´ RDS ì—°ê²° í…ŒìŠ¤íŠ¸ (ì¬ì‹œë„ ë¡œì§)
        echo "ğŸ” SSH í„°ë„ì„ í†µí•œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
        DB_CONNECTED=false
        for i in {1..5}; do
          if PGPASSWORD="${{ secrets.DB_PASSWORD }}" psql \
            -h localhost \
            -p $LOCAL_PORT \
            -U "$DB_USER" \
            -d "$DB_NAME" \
            -c "SELECT version();" \
            -v ON_ERROR_STOP=1 2>/dev/null; then
            echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ (ì‹œë„ $i/5)"
            DB_CONNECTED=true
            break
          else
            echo "âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ $i/5)"
            # ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ì¶œë ¥
            echo "ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:"
            PGPASSWORD="${{ secrets.DB_PASSWORD }}" psql \
              -h localhost \
              -p $LOCAL_PORT \
              -U "$DB_USER" \
              -d "$DB_NAME" \
              -c "SELECT version();" 2>&1 || true
            
            if [ $i -lt 5 ]; then
              echo "3ì´ˆ í›„ ì¬ì‹œë„..."
              sleep 3
            fi
          fi
        done
        
        if [ "$DB_CONNECTED" != "true" ]; then
          echo "âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìµœì¢… ì‹¤íŒ¨"
          echo "ğŸ” ì—°ê²° ì •ë³´:"
          echo "  ë¡œì»¬ í¬íŠ¸: $LOCAL_PORT"
          echo "  DB í˜¸ìŠ¤íŠ¸: $DB_HOST"
          echo "  DB ì‚¬ìš©ì: $DB_USER"
          echo "  DB ì´ë¦„: $DB_NAME"
          kill $SSH_PID 2>/dev/null
          rm -f bastion_key.pem
          exit 1
        fi
        
        # ê¸°ì¡´ í…Œì´ë¸” í™•ì¸
        echo "ğŸ” ê¸°ì¡´ í…Œì´ë¸” í™•ì¸ ì¤‘..."
        EXISTING_TABLES=$(PGPASSWORD="${{ secrets.DB_PASSWORD }}" psql \
          -h localhost \
          -p $LOCAL_PORT \
          -U "$DB_USER" \
          -d "$DB_NAME" \
          -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public' AND table_name IN ('users', 'posts', 'images', 'files');" \
          -v ON_ERROR_STOP=1 | tr -d ' ')
        
        echo "ğŸ“Š ê¸°ì¡´ í…Œì´ë¸” ê°œìˆ˜: $EXISTING_TABLES/4"
        
        if [ "$EXISTING_TABLES" -lt "4" ]; then
          echo "ğŸ“ ìŠ¤í‚¤ë§ˆ íŒŒì¼ ì ìš© ì¤‘..."
          if PGPASSWORD="${{ secrets.DB_PASSWORD }}" psql \
            -h localhost \
            -p $LOCAL_PORT \
            -U "$DB_USER" \
            -d "$DB_NAME" \
            -f server1/files/schema.sql \
            -v ON_ERROR_STOP=1; then
            echo "âœ… ìŠ¤í‚¤ë§ˆ ì ìš© ì™„ë£Œ"
          else
            echo "âŒ ìŠ¤í‚¤ë§ˆ ì ìš© ì‹¤íŒ¨"
            kill $SSH_PID 2>/dev/null
            rm -f bastion_key.pem
            exit 1
          fi

        else
          echo "â„¹ï¸ ëª¨ë“  í…Œì´ë¸”ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤ ($EXISTING_TABLES/4). ìŠ¤í‚¤ë§ˆ ì ìš©ì„ ê±´ë„ˆëœë‹ˆë‹¤."
        fi

        # ì •ë¦¬ ì‘ì—…
        echo "ğŸ§¹ ì •ë¦¬ ì‘ì—… ì¤‘..."
        kill $SSH_PID 2>/dev/null
        rm -f bastion_key.pem

        echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì‘ì—… ì™„ë£Œ"

    # ===============================================
    # kubectl ë° Helm ì„¤ì¹˜
    # ===============================================
    - name: Install kubectl and Helm
      run: |
          echo "ğŸ”§ kubectl ë° Helm ì„¤ì¹˜ ì¤‘..."

          # kubectl ì„¤ì¹˜
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

          # Helm ì„¤ì¹˜
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

          echo "âœ… kubectl ë° Helm ì„¤ì¹˜ ì™„ë£Œ"
          kubectl version --client
          helm version

    - name: Update kubeconfig for EKS
      run: |
          echo "ğŸ”§ EKS í´ëŸ¬ìŠ¤í„° kubeconfig ì—…ë°ì´íŠ¸ ì¤‘..."

          # í˜„ì¬ AWS ìê²© ì¦ëª… í™•ì¸
          echo "ğŸ” í˜„ì¬ AWS ìê²© ì¦ëª… í™•ì¸..."
          aws sts get-caller-identity

          # EKS í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì¡°íšŒ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
          echo "ğŸ” EKS í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì¤‘..."

          # ë°©ë²• 1: í´ëŸ¬ìŠ¤í„° ëª©ë¡ì—ì„œ ì²« ë²ˆì§¸ ì¡°íšŒ
          EKS_CLUSTER_NAME=$(aws eks list-clusters --query 'clusters[0]' --output text 2>/dev/null || echo "")

          # ë°©ë²• 2: íŠ¹ì • ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ
          if [ -z "$EKS_CLUSTER_NAME" ] || [ "$EKS_CLUSTER_NAME" == "None" ]; then
            EKS_CLUSTER_NAME="${{ env.EKS_CLUSTER_NAME }}"
            echo "ê¸°ë³¸ í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì‚¬ìš©: $EKS_CLUSTER_NAME"
          fi

          # í´ëŸ¬ìŠ¤í„° ì¡´ì¬ í™•ì¸
          if ! aws eks describe-cluster --name "$EKS_CLUSTER_NAME" --region ${{ secrets.AWS_REGION }} >/dev/null 2>&1; then
            echo "âŒ EKS í´ëŸ¬ìŠ¤í„° '$EKS_CLUSTER_NAME'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            echo "ì‚¬ìš© ê°€ëŠ¥í•œ í´ëŸ¬ìŠ¤í„° ëª©ë¡:"
            aws eks list-clusters --region ${{ secrets.AWS_REGION }}
            exit 1
          fi

          echo "âœ… EKS í´ëŸ¬ìŠ¤í„°: $EKS_CLUSTER_NAME"
          echo "EKS_CLUSTER_NAME=$EKS_CLUSTER_NAME" >> $GITHUB_ENV

          # í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
          CLUSTER_STATUS=$(aws eks describe-cluster --name "$EKS_CLUSTER_NAME" --region ${{ secrets.AWS_REGION }} --query 'cluster.status' --output text)
          echo "í´ëŸ¬ìŠ¤í„° ìƒíƒœ: $CLUSTER_STATUS"

          if [ "$CLUSTER_STATUS" != "ACTIVE" ]; then
            echo "âŒ í´ëŸ¬ìŠ¤í„°ê°€ ACTIVE ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤: $CLUSTER_STATUS"
            exit 1
          fi

          # IAM ì—­í• ê³¼ OIDC ê³µê¸‰ì ì •ë³´ í™•ì¸
          echo "ğŸ” IAM ì—­í• ê³¼ OIDC ì„¤ì • í™•ì¸ ì¤‘..."
          CLUSTER_OIDC_ISSUER=$(aws eks describe-cluster --name "$EKS_CLUSTER_NAME" --region ${{ secrets.AWS_REGION }} --query 'cluster.identity.oidc.issuer' --output text)
          echo "OIDC ë°œí–‰ì: $CLUSTER_OIDC_ISSUER"
          
          # kubeconfig ì—…ë°ì´íŠ¸ (í˜„ì¬ OIDC ìê²© ì¦ëª… ì‚¬ìš©)
          echo "ğŸ”§ kubeconfig ì—…ë°ì´íŠ¸ ì¤‘ (OIDC ìê²© ì¦ëª… ì‚¬ìš©)..."
          aws eks update-kubeconfig \
            --region ${{ secrets.AWS_REGION }} \
            --name "$EKS_CLUSTER_NAME" \
            --verbose

          # AWS ìê²© ì¦ëª… í™•ì¸
          echo "ğŸ” í˜„ì¬ AWS ìê²© ì¦ëª… í™•ì¸..."
          aws sts get-caller-identity
          
          # í´ëŸ¬ìŠ¤í„° ì—°ê²° í…ŒìŠ¤íŠ¸ (ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ í¬í•¨)
          echo "ğŸ” í´ëŸ¬ìŠ¤í„° ì—°ê²° í…ŒìŠ¤íŠ¸..."
          if ! kubectl cluster-info --request-timeout=30s; then
            echo "âŒ kubectl cluster-info ì‹¤íŒ¨. ì¶”ê°€ ì§„ë‹¨ ì •ë³´:"
            
            # kubectl ì„¤ì • í™•ì¸
            echo "kubectl ì„¤ì • í™•ì¸:"
            kubectl config view --minify
            
            # í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ í™•ì¸
            echo "í˜„ì¬ ì»¨í…ìŠ¤íŠ¸:"
            kubectl config current-context
            
            # í´ëŸ¬ìŠ¤í„° ì—”ë“œí¬ì¸íŠ¸ ì§ì ‘ í…ŒìŠ¤íŠ¸
            CLUSTER_ENDPOINT=$(aws eks describe-cluster --name "$EKS_CLUSTER_NAME" --region ${{ secrets.AWS_REGION }} --query 'cluster.endpoint' --output text)
            echo "í´ëŸ¬ìŠ¤í„° ì—”ë“œí¬ì¸íŠ¸: $CLUSTER_ENDPOINT"
            
            # kubeconfig ë‹¤ì‹œ ì„¤ì •
            echo "ğŸ”§ kubeconfig ì¬ì„¤ì •..."
            aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name "$EKS_CLUSTER_NAME" --verbose
            
            # aws-auth ConfigMap ìƒíƒœ í™•ì¸
            echo "ğŸ” aws-auth ConfigMap í™•ì¸..."
            kubectl get configmap aws-auth -n kube-system -o yaml || echo "aws-auth ConfigMap ì—†ìŒ"
            
            exit 1
          fi

          # aws-auth ConfigMap ìƒíƒœ í™•ì¸ (ì •ë³´ì„±)
          echo "ğŸ” aws-auth ConfigMap ìƒíƒœ í™•ì¸..."
          kubectl get configmap aws-auth -n kube-system -o yaml | head -20 || echo "aws-auth ConfigMap ì¡°íšŒ ì‹¤íŒ¨"
          
          echo "âœ… EKS í´ëŸ¬ìŠ¤í„° ì—°ê²° ì„±ê³µ"

          echo "ğŸ” ë…¸ë“œ ìƒíƒœ í™•ì¸..."
          kubectl get nodes --show-labels

      # ===============================================
      # í¼ë¸”ë¦­ ì„œë¸Œë„· ì •ë³´ ì¡°íšŒ
      # ===============================================
    - name: Get Subnet Information
      run: |
          echo "ğŸ” ì„œë¸Œë„· ì •ë³´ ì¡°íšŒ ì¤‘..."
          
          # í¼ë¸”ë¦­ ì„œë¸Œë„· ì¡°íšŒ (ALBìš©) - ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„
          echo "ğŸ” í¼ë¸”ë¦­ ì„œë¸Œë„· ì¡°íšŒ ì¤‘..."
          
          # EKS í´ëŸ¬ìŠ¤í„°ì˜ VPC ì¡°íšŒ
          echo "ğŸ” EKS í´ëŸ¬ìŠ¤í„° VPC ì¡°íšŒ ì¤‘..."
          EKS_VPC_ID=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query "cluster.resourcesVpcConfig.vpcId" --output text 2>/dev/null || echo "")
          
          if [ -z "$EKS_VPC_ID" ] || [ "$EKS_VPC_ID" == "None" ]; then
            echo "âš ï¸ EKS í´ëŸ¬ìŠ¤í„° VPCë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ê³„ì •ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤."
            VPC_FILTER=""
          else
            echo "âœ… EKS VPC ë°œê²¬: $EKS_VPC_ID"
            VPC_FILTER="Name=vpc-id,Values=$EKS_VPC_ID"
          fi
          
          # ë°©ë²• 1: Type=public íƒœê·¸ë¡œ ì¡°íšŒ (EKS VPC ë‚´ì—ì„œ, ìµœëŒ€ 3ê°œ)
          if [ -n "$VPC_FILTER" ]; then
            PUBLIC_SUBNETS=$(aws ec2 describe-subnets \
              --filters "Name=tag:Type,Values=public" "Name=state,Values=available" "$VPC_FILTER" \
              --query "Subnets[:3].SubnetId" \
              --output text | tr '\t' ',' | sed 's/,$//')
          else
            PUBLIC_SUBNETS=$(aws ec2 describe-subnets \
              --filters "Name=tag:Type,Values=public" "Name=state,Values=available" \
              --query "Subnets[:3].SubnetId" \
              --output text | tr '\t' ',' | sed 's/,$//')
          fi
          
          if [ -z "$PUBLIC_SUBNETS" ]; then
            # ë°©ë²• 2: kubernetes.io/role/elb íƒœê·¸ë¡œ ì¡°íšŒ (EKS VPC ë‚´ì—ì„œ)
            echo "âš ï¸ Type=public íƒœê·¸ë¡œ ì°¾ì§€ ëª»í•¨. kubernetes.io/role/elb íƒœê·¸ë¡œ ì¬ì‹œë„..."
            if [ -n "$VPC_FILTER" ]; then
              PUBLIC_SUBNETS=$(aws ec2 describe-subnets \
                --filters "Name=tag:kubernetes.io/role/elb,Values=1" "Name=state,Values=available" "$VPC_FILTER" \
                --query "Subnets[:3].SubnetId" \
                --output text | tr '\t' ',' | sed 's/,$//')
            else
              PUBLIC_SUBNETS=$(aws ec2 describe-subnets \
                --filters "Name=tag:kubernetes.io/role/elb,Values=1" "Name=state,Values=available" \
                --query "Subnets[:3].SubnetId" \
                --output text | tr '\t' ',' | sed 's/,$//')
            fi
          fi
          
          if [ -z "$PUBLIC_SUBNETS" ]; then
            # ë°©ë²• 3: ë¼ìš°íŠ¸ í…Œì´ë¸”ì„ í†µí•´ ì¸í„°ë„· ê²Œì´íŠ¸ì›¨ì´ê°€ ìˆëŠ” ì„œë¸Œë„· ì°¾ê¸° (EKS VPC ë‚´ì—ì„œ)
            echo "âš ï¸ íƒœê·¸ë¡œ ì°¾ì§€ ëª»í•¨. ë¼ìš°íŠ¸ í…Œì´ë¸” ë¶„ì„ìœ¼ë¡œ í¼ë¸”ë¦­ ì„œë¸Œë„· ì°¾ëŠ” ì¤‘..."
            if [ -n "$EKS_VPC_ID" ]; then
              PUBLIC_SUBNETS_RAW=$(aws ec2 describe-route-tables \
                --filters "Name=route.gateway-id,Values=igw-*" "Name=vpc-id,Values=$EKS_VPC_ID" \
                --query "RouteTables[*].Associations[?SubnetId!=null].SubnetId" \
                --output text | tr '\n' ' ' | tr '\t' ' ')
            else
              PUBLIC_SUBNETS_RAW=$(aws ec2 describe-route-tables \
                --filters "Name=route.gateway-id,Values=igw-*" \
                --query "RouteTables[*].Associations[?SubnetId!=null].SubnetId" \
                --output text | tr '\n' ' ' | tr '\t' ' ')
            fi
            
            # ê°€ìš©ì˜ì—­ë³„ë¡œ ì„œë¸Œë„· ì„ íƒ (ì¤‘ë³µ AZ ë°©ì§€)
            if [ -n "$PUBLIC_SUBNETS_RAW" ]; then
              UNIQUE_AZ_SUBNETS=""
              USED_AZS=""
              for subnet in $PUBLIC_SUBNETS_RAW; do
                AZ=$(aws ec2 describe-subnets --subnet-ids $subnet --query 'Subnets[0].AvailabilityZone' --output text 2>/dev/null)
                if [ -n "$AZ" ] && [[ ! "$USED_AZS" == *"$AZ"* ]]; then
                  UNIQUE_AZ_SUBNETS="$UNIQUE_AZ_SUBNETS $subnet"
                  USED_AZS="$USED_AZS $AZ"
                  # ìµœëŒ€ 3ê°œ AZê¹Œì§€ë§Œ
                  if [ $(echo $UNIQUE_AZ_SUBNETS | wc -w) -ge 3 ]; then
                    break
                  fi
                fi
              done
              PUBLIC_SUBNETS=$(echo "$UNIQUE_AZ_SUBNETS" | tr ' ' ',' | sed 's/^,//' | sed 's/,$//')
            fi
          fi
          
          if [ -z "$PUBLIC_SUBNETS" ]; then
            # ë°©ë²• 4: ëª¨ë“  í¼ë¸”ë¦­ ì„œë¸Œë„·ì—ì„œ ê°€ìš©ì˜ì—­ë³„ë¡œ 1ê°œì”© ì„ íƒ
            echo "âš ï¸ íƒœê·¸ ê¸°ë°˜ ì¡°íšŒ ì‹¤íŒ¨. ëª¨ë“  í¼ë¸”ë¦­ ì„œë¸Œë„·ì—ì„œ ê°€ìš©ì˜ì—­ë³„ë¡œ ì„ íƒ ì¤‘..."
            
            # EKS VPC ë‚´ì—ì„œ ìš°ì„  ì¡°íšŒ, ì‹¤íŒ¨í•˜ë©´ ì „ì²´ ê³„ì •ì—ì„œ ì¡°íšŒ
            VPC_FILTER_OPTION=""
            if [ -n "$EKS_VPC_ID" ] && [ "$EKS_VPC_ID" != "None" ]; then
              VPC_FILTER_OPTION="Name=vpc-id,Values=$EKS_VPC_ID"
              echo "ğŸ” EKS VPC($EKS_VPC_ID) ë‚´ì—ì„œ í¼ë¸”ë¦­ ì„œë¸Œë„· ì¡°íšŒ ì¤‘..."
            else
              echo "ğŸ” ì „ì²´ ê³„ì •ì—ì„œ í¼ë¸”ë¦­ ì„œë¸Œë„· ì¡°íšŒ ì¤‘..."
            fi
            
            # ëª¨ë“  ì„œë¸Œë„· ì¡°íšŒ (State=availableë§Œ)
            ALL_SUBNETS=$(aws ec2 describe-subnets \
              --filters "Name=state,Values=available" $VPC_FILTER_OPTION \
              --query "Subnets[*].[SubnetId,AvailabilityZone,MapPublicIpOnLaunch]" \
              --output text)
            
            if [ -n "$ALL_SUBNETS" ]; then
              UNIQUE_AZ_SUBNETS=""
              USED_AZS=""
              
              echo "$ALL_SUBNETS" | while read subnet_id az map_public; do
                # MapPublicIpOnLaunchê°€ trueì¸ ì„œë¸Œë„·ë§Œ (í¼ë¸”ë¦­ ì„œë¸Œë„·)
                if [ "$map_public" = "True" ] && [[ ! "$USED_AZS" == *"$az"* ]]; then
                  UNIQUE_AZ_SUBNETS="$UNIQUE_AZ_SUBNETS $subnet_id"
                  USED_AZS="$USED_AZS $az"
                  echo "âœ… ê°€ìš©ì˜ì—­ $azì—ì„œ ì„œë¸Œë„· $subnet_id ì„ íƒ"
                  
                  # ìµœëŒ€ 3ê°œ AZê¹Œì§€ë§Œ
                  if [ $(echo $UNIQUE_AZ_SUBNETS | wc -w) -ge 3 ]; then
                    break
                  fi
                fi
              done
              
              if [ -n "$UNIQUE_AZ_SUBNETS" ]; then
                PUBLIC_SUBNETS=$(echo "$UNIQUE_AZ_SUBNETS" | tr ' ' ',' | sed 's/^,//' | sed 's/,$//')
                echo "âœ… ìë™ ì„ íƒëœ í¼ë¸”ë¦­ ì„œë¸Œë„·: $PUBLIC_SUBNETS"
              fi
            fi
            
            if [ -z "$PUBLIC_SUBNETS" ]; then
              echo "âŒ ì‚¬ìš© ê°€ëŠ¥í•œ í¼ë¸”ë¦­ ì„œë¸Œë„·ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
              echo "ğŸ” VPCì— í¼ë¸”ë¦­ ì„œë¸Œë„·ì´ ìƒì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
              echo "ğŸ” ë˜ëŠ” ì„œë¸Œë„·ì— ë‹¤ìŒ íƒœê·¸ë¥¼ ì¶”ê°€í•˜ì„¸ìš”:"
              echo "   - Type=public ë˜ëŠ”"
              echo "   - kubernetes.io/role/elb=1"
              exit 1
            fi
          else
            echo "âœ… í¼ë¸”ë¦­ ì„œë¸Œë„· ë°œê²¬: $PUBLIC_SUBNETS"
          fi
          
          # í™˜ê²½ë³€ìˆ˜ ì•ˆì „í•˜ê²Œ ì €ì¥
          if [ -n "$PUBLIC_SUBNETS" ] && [ "$PUBLIC_SUBNETS" != "null" ]; then
            # ì„œë¸Œë„· ê°œìˆ˜ í™•ì¸
            SUBNET_COUNT=$(echo "$PUBLIC_SUBNETS" | tr ',' '\n' | wc -l)
            echo "ğŸ“Š ì„ íƒëœ ì„œë¸Œë„· ê°œìˆ˜: $SUBNET_COUNTê°œ"
            echo "ğŸ“‹ ì„œë¸Œë„· ëª©ë¡: $PUBLIC_SUBNETS"
            
            # GITHUB_ENVì— ì•ˆì „í•˜ê²Œ ì €ì¥
            echo "PUBLIC_SUBNETS=$PUBLIC_SUBNETS" >> "$GITHUB_ENV"
          else
            echo "âŒ ìœ íš¨í•œ í¼ë¸”ë¦­ ì„œë¸Œë„·ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            exit 1
          fi

      # ===============================================
      # Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
      # ===============================================
    - name: Generate Kubernetes manifests
      run: |
          echo "ğŸ“ Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì¤‘..."

          # Namespace ìƒì„±
          echo "apiVersion: v1" > namespace.yaml
          echo "kind: Namespace" >> namespace.yaml
          echo "metadata:" >> namespace.yaml
          echo "  name: ${{ env.PROJECT_NAME }}" >> namespace.yaml
          
          # ConfigMap ìƒì„± (í™˜ê²½ë³€ìˆ˜)
          echo "apiVersion: v1" > configmap.yaml
          echo "kind: ConfigMap" >> configmap.yaml
          echo "metadata:" >> configmap.yaml
          echo "  name: ${{ env.PROJECT_NAME }}-config" >> configmap.yaml
          echo "  namespace: ${{ env.PROJECT_NAME }}" >> configmap.yaml
          echo "data:" >> configmap.yaml
          echo '  DB_HOST: "${{ env.RDS_ENDPOINT }}"' >> configmap.yaml
          echo "  DB_PORT: \"${{ env.DB_PORT }}\"" >> configmap.yaml
          echo "  DB_NAME: \"${{ env.DB_NAME }}\"" >> configmap.yaml
          echo "  DB_USER: \"${{ env.DB_USER }}\"" >> configmap.yaml
          echo '  AWS_REGION: "${{ secrets.AWS_REGION }}"' >> configmap.yaml
          echo "  AWS_S3_BUCKET: \"${{ env.S3_BUCKET_NAME }}\"" >> configmap.yaml
          echo '  AWS_S3_REGION: "${{ secrets.AWS_REGION }}"' >> configmap.yaml
          echo '  STORAGE_TYPE: "s3"' >> configmap.yaml
          echo '  APP_ENV: "production"' >> configmap.yaml
          echo '  APP_DEBUG: "false"' >> configmap.yaml
          echo '  PHP_MEMORY_LIMIT: "256M"' >> configmap.yaml
          echo '  PHP_MAX_EXECUTION_TIME: "30"' >> configmap.yaml
          echo '  PHP_TIMEZONE: "Asia/Seoul"' >> configmap.yaml
          echo '  UPLOAD_MAX_SIZE: "10M"' >> configmap.yaml
          echo '  SESSION_LIFETIME: "7200"' >> configmap.yaml
        
          # Secret ìƒì„± (DB íŒ¨ìŠ¤ì›Œë“œ)
          echo "apiVersion: v1" > secret.yaml
          echo "kind: Secret" >> secret.yaml
          echo "metadata:" >> secret.yaml
          echo "  name: ${{ env.PROJECT_NAME }}-secret" >> secret.yaml
          echo "  namespace: ${{ env.PROJECT_NAME }}" >> secret.yaml
          echo "type: Opaque" >> secret.yaml
          echo "data:" >> secret.yaml
          echo "  DB_PASSWORD: $(echo -n '${{ secrets.DB_PASSWORD }}' | base64)" >> secret.yaml
          
          # Deployment ìƒì„±
          echo "apiVersion: apps/v1" > deployment.yaml
          echo "kind: Deployment" >> deployment.yaml
          echo "metadata:" >> deployment.yaml
          echo "  name: ${{ env.PROJECT_NAME }}-app" >> deployment.yaml
          echo "  namespace: ${{ env.PROJECT_NAME }}" >> deployment.yaml
          echo "  labels:" >> deployment.yaml
          echo "    app: ${{ env.PROJECT_NAME }}-app" >> deployment.yaml
          echo "spec:" >> deployment.yaml
          echo "  replicas: 2" >> deployment.yaml
          echo "  selector:" >> deployment.yaml
          echo "    matchLabels:" >> deployment.yaml
          echo "      app: ${{ env.PROJECT_NAME }}-app" >> deployment.yaml
          echo "  template:" >> deployment.yaml
          echo "    metadata:" >> deployment.yaml
          echo "      labels:" >> deployment.yaml
          echo "        app: ${{ env.PROJECT_NAME }}-app" >> deployment.yaml
          echo "    spec:" >> deployment.yaml
          echo "      serviceAccountName: ${{ env.PROJECT_NAME }}-service-account" >> deployment.yaml
          echo "      containers:" >> deployment.yaml
          echo "      - name: php-app" >> deployment.yaml
          echo "        image: ${{ steps.build-image.outputs.image }}" >> deployment.yaml
          echo "        ports:" >> deployment.yaml
          echo "        - containerPort: 80" >> deployment.yaml  
          echo "          name: http" >> deployment.yaml
          echo "        envFrom:" >> deployment.yaml
          echo "        - configMapRef:" >> deployment.yaml
          echo "            name: ${{ env.PROJECT_NAME }}-config" >> deployment.yaml
          echo "        - secretRef:" >> deployment.yaml
          echo "            name: ${{ env.PROJECT_NAME }}-secret" >> deployment.yaml
          echo "        livenessProbe:" >> deployment.yaml
          echo "          tcpSocket:" >> deployment.yaml
          echo "            port: 80" >> deployment.yaml
          echo "          initialDelaySeconds: 120" >> deployment.yaml
          echo "          periodSeconds: 60" >> deployment.yaml
          echo "          timeoutSeconds: 10" >> deployment.yaml
          echo "          failureThreshold: 5" >> deployment.yaml
          echo "        readinessProbe:" >> deployment.yaml
          echo "          tcpSocket:" >> deployment.yaml
          echo "            port: 80" >> deployment.yaml
          echo "          initialDelaySeconds: 60" >> deployment.yaml
          echo "          periodSeconds: 30" >> deployment.yaml
          echo "          timeoutSeconds: 5" >> deployment.yaml
          echo "          failureThreshold: 3" >> deployment.yaml
          echo "        resources:" >> deployment.yaml
          echo "          requests:" >> deployment.yaml
          echo '            memory: "256Mi"' >> deployment.yaml
          echo '            cpu: "250m"' >> deployment.yaml
          echo "          limits:" >> deployment.yaml
          echo '            memory: "512Mi"' >> deployment.yaml
          echo '            cpu: "500m"' >> deployment.yaml
          echo "        securityContext:" >> deployment.yaml
          echo "          runAsNonRoot: false" >> deployment.yaml
          echo "          allowPrivilegeEscalation: false" >> deployment.yaml
          echo "          readOnlyRootFilesystem: false" >> deployment.yaml

          # Service ìƒì„± (Ingress ê¸°ë°˜ì´ë¯€ë¡œ ClusterIP ì‚¬ìš©)
          echo "apiVersion: v1" > service.yaml
          echo "kind: Service" >> service.yaml
          echo "metadata:" >> service.yaml
          echo "  name: ${{ env.PROJECT_NAME }}-service" >> service.yaml
          echo "  namespace: ${{ env.PROJECT_NAME }}" >> service.yaml
          echo "  labels:" >> service.yaml
          echo "    app: ${{ env.PROJECT_NAME }}-app" >> service.yaml
          echo "spec:" >> service.yaml
          echo "  type: ClusterIP" >> service.yaml
          echo "  ports:" >> service.yaml
          echo "  - port: 80" >> service.yaml
          echo "    targetPort: 80" >> service.yaml
          echo "    protocol: TCP" >> service.yaml
          echo "    name: http" >> service.yaml
          echo "  selector:" >> service.yaml
          echo "    app: ${{ env.PROJECT_NAME }}-app" >> service.yaml

          # Ingress ìƒì„± (AWS Load Balancer Controller ì‚¬ìš©)
          echo "apiVersion: networking.k8s.io/v1" > ingress.yaml
          echo "kind: Ingress" >> ingress.yaml
          echo "metadata:" >> ingress.yaml
          echo "  name: ${{ env.PROJECT_NAME }}-ingress" >> ingress.yaml
          echo "  namespace: ${{ env.PROJECT_NAME }}" >> ingress.yaml
          echo "  annotations:" >> ingress.yaml
          echo "    # AWS Application Load Balancer ì„¤ì •" >> ingress.yaml
          echo "    alb.ingress.kubernetes.io/scheme: internet-facing" >> ingress.yaml
          echo "    alb.ingress.kubernetes.io/target-type: ip" >> ingress.yaml
          echo '    alb.ingress.kubernetes.io/listen-ports: '"'"'[{"HTTP": 80}]'"'"'' >> ingress.yaml
          echo "    alb.ingress.kubernetes.io/subnets: ${{ env.PUBLIC_SUBNETS }}" >> ingress.yaml
          echo "    " >> ingress.yaml
          echo "    # Health Check ì„¤ì • (PHP ì• í”Œë¦¬ì¼€ì´ì…˜)" >> ingress.yaml
          echo "    alb.ingress.kubernetes.io/healthcheck-path: ${{ env.HEALTH_CHECK_PATH }}" >> ingress.yaml
          echo "    alb.ingress.kubernetes.io/healthcheck-interval-seconds: '30'" >> ingress.yaml
          echo "    alb.ingress.kubernetes.io/healthcheck-timeout-seconds: '10'" >> ingress.yaml
          echo "    alb.ingress.kubernetes.io/healthy-threshold-count: '2'" >> ingress.yaml
          echo "    alb.ingress.kubernetes.io/unhealthy-threshold-count: '3'" >> ingress.yaml
          echo "    alb.ingress.kubernetes.io/healthcheck-protocol: HTTP" >> ingress.yaml
          echo "    alb.ingress.kubernetes.io/healthcheck-port: '80'" >> ingress.yaml
          echo "    " >> ingress.yaml
          echo "    # Load Balancer ì„¤ì •" >> ingress.yaml
          echo "    alb.ingress.kubernetes.io/load-balancer-name: ${{ env.PROJECT_NAME }}-ingress-alb" >> ingress.yaml
          echo '    alb.ingress.kubernetes.io/target-group-attributes: "stickiness.enabled=false,deregistration_delay.timeout_seconds=60,load_balancing.algorithm.type=round_robin,slow_start.duration_seconds=30"' >> ingress.yaml
          echo "spec:" >> ingress.yaml
          echo "  ingressClassName: alb" >> ingress.yaml
          echo "  rules:" >> ingress.yaml
          echo "  - http:" >> ingress.yaml
          echo "      paths:" >> ingress.yaml
          echo "      - path: /" >> ingress.yaml
          echo "        pathType: Prefix" >> ingress.yaml
          echo "        backend:" >> ingress.yaml
          echo "          service:" >> ingress.yaml
          echo "            name: ${{ env.PROJECT_NAME }}-service" >> ingress.yaml
          echo "            port:" >> ingress.yaml
          echo "              number: 80" >> ingress.yaml

          echo "âœ… Ingress ê¸°ë°˜ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ"

          # ServiceAccount ìƒì„± (IRSAìš©)
          echo "apiVersion: v1" > serviceaccount.yaml
          echo "kind: ServiceAccount" >> serviceaccount.yaml
          echo "metadata:" >> serviceaccount.yaml
          echo "  name: ${{ env.PROJECT_NAME }}-service-account" >> serviceaccount.yaml
          echo "  namespace: ${{ env.PROJECT_NAME }}" >> serviceaccount.yaml
          echo "  annotations:" >> serviceaccount.yaml
          echo "    eks.amazonaws.com/role-arn: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/${{ env.IAM_ROLE_NAME }}" >> serviceaccount.yaml

          echo "âœ… ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì™„ë£Œ"

      # ===============================================
      # EKSì— ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ (main ë¸Œëœì¹˜ì¼ ë•Œë§Œ)
      # ===============================================
    - name: Deploy to EKS
      if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
      run: |
          echo "ğŸš€ EKSì— ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ì¤‘..."

          # Namespace ë¨¼ì € ìƒì„±
          kubectl apply -f namespace.yaml

          # ë‚˜ë¨¸ì§€ ë¦¬ì†ŒìŠ¤ ë°°í¬
          kubectl apply -f serviceaccount.yaml
          kubectl apply -f configmap.yaml
          kubectl apply -f secret.yaml
          kubectl apply -f deployment.yaml
          
          # Service ë°°í¬ ì „ AWS Load Balancer Controller ì›¹í›… íŒ¨ì¹˜
          echo "ğŸ”§ AWS Load Balancer Controller ì›¹í›… ì„¤ì • í™•ì¸ ë° íŒ¨ì¹˜..."
          
          # ì›¹í›… ì„¤ì • í™•ì¸
          echo "í˜„ì¬ ì›¹í›… ì„¤ì • í™•ì¸:"
          kubectl get validatingwebhookconfigurations aws-load-balancer-webhook -o yaml || echo "ValidatingWebhook ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
          kubectl get mutatingwebhookconfigurations aws-load-balancer-webhook -o yaml || echo "MutatingWebhook ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
          
          # ì›¹í›… ë¹„í™œì„±í™” (ì„ì‹œ)
          echo "ì›¹í›… ì„ì‹œ ë¹„í™œì„±í™”..."
          kubectl delete validatingwebhookconfigurations aws-load-balancer-webhook || echo "ValidatingWebhook ì‚­ì œ ì‹¤íŒ¨ ë˜ëŠ” ì´ë¯¸ ì‚­ì œë¨"
          kubectl delete mutatingwebhookconfigurations aws-load-balancer-webhook || echo "MutatingWebhook ì‚­ì œ ì‹¤íŒ¨ ë˜ëŠ” ì´ë¯¸ ì‚­ì œë¨"
          
          # Service ë°°í¬
          echo "Service ë°°í¬ ì¤‘..."
          kubectl apply -f service.yaml
          
          # ì›¹í›… ì¬ìƒì„± (AWS Load Balancer Controllerê°€ ìë™ìœ¼ë¡œ ì¬ìƒì„±)
          echo "AWS Load Balancer Controller ì¬ì‹œì‘í•˜ì—¬ ì›¹í›… ì¬ìƒì„±..."
          kubectl rollout restart deployment/aws-load-balancer-controller -n kube-system || echo "Load Balancer Controller ì¬ì‹œì‘ ì‹¤íŒ¨"

          # Ingress ë°°í¬ (AWS Load Balancer Controllerë¡œ ALB ìƒì„±)
          echo "ğŸ”— Ingress ë¦¬ì†ŒìŠ¤ ë°°í¬ ì¤‘..."
          
          # Ingress ë°°í¬ ì „ ì‚¬ì „ ê²€ì¦
          echo "ğŸ” Ingress ë°°í¬ ì „ ì‚¬ì „ ê²€ì¦..."
          echo "Namespace í™•ì¸:"
          kubectl get namespace ${{ env.PROJECT_NAME }} || true
          echo "Service í™•ì¸:"
          kubectl get service ${{ env.PROJECT_NAME }}-service -n ${{ env.PROJECT_NAME }} || true
          echo "IngressClass í™•ì¸:"
          kubectl get ingressclass alb || true
          echo "ValidatingWebhookConfiguration í™•ì¸:"
          kubectl get validatingwebhookconfigurations | grep -E "(ingress|elb|load-balancer|aws)" || echo "AWS LB Controller Webhook ì—†ìŒ"
          
          # Ingress ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë‚´ìš© í™•ì¸
          echo "ğŸ” Ingress ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë‚´ìš©:"
          cat ingress.yaml
          
          # Ingress ë°°í¬
          echo "ğŸš€ Ingress ë°°í¬ ì‹œì‘..."
          if kubectl apply -f ingress.yaml; then
            echo "âœ… Ingress ë¦¬ì†ŒìŠ¤ ìƒì„± ì„±ê³µ"
            
            # ìƒì„±ëœ Ingress ì¦‰ì‹œ í™•ì¸
            echo "ğŸ” ìƒì„±ëœ Ingress ìƒíƒœ í™•ì¸:"
            kubectl get ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }} -o yaml || echo "Ingress ì¡°íšŒ ì‹¤íŒ¨"
            
            # Ingressì™€ ALB ë™ê¸°í™” ìƒíƒœ ì²´í¬
            echo "ğŸ” Ingressì™€ ALB ë™ê¸°í™” ìƒíƒœ ì²´í¬ ì¤‘..."
            
            # Ingress finalizer ìƒíƒœ í™•ì¸
            ingress_finalizers=$(kubectl get ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }} -o jsonpath='{.metadata.finalizers}' 2>/dev/null || echo "")
            if [[ -z "$ingress_finalizers" ]]; then
              echo "âš ï¸ Ingress finalizerê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AWS Load Balancer Controller ìƒíƒœ í™•ì¸ ì¤‘..."
              kubectl describe ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }} | grep -A 10 "Events:" || true
              
              # Controller ë¡œê·¸ í™•ì¸
              echo "ğŸ” Controller ë¡œê·¸ í™•ì¸:"
              kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --tail=10 || true
            else
              echo "âœ… Ingress finalizer ì„¤ì •ë¨: $ingress_finalizers"
            fi
            
            # ALB ìƒì„± ëŒ€ê¸° (ì´ 20ë¶„)
            echo "â³ AWS Load Balancer Controllerì— ì˜í•œ ALB ìƒì„± ëŒ€ê¸° ì¤‘..."
            echo "â„¹ï¸ ALB ìƒì„± ë° í”„ë¡œë¹„ì €ë‹ì—ëŠ” 5-10ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            ALB_CREATED=false
            ALB_PROVISIONING=false
            for i in {1..40}; do
              ALB_DNS=$(kubectl get ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
              
              if [ -n "$ALB_DNS" ] && [ "$ALB_DNS" != "null" ]; then
                if [ "$ALB_PROVISIONING" != "true" ]; then
                  echo "ğŸ¯ ALB DNS ì£¼ì†Œ í• ë‹¹ ì™„ë£Œ: $ALB_DNS"
                  echo "â³ ì´ì œ ALB í”„ë¡œë¹„ì €ë‹ ë° í—¬ìŠ¤ì²´í¬ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦½ë‹ˆë‹¤..."
                  ALB_PROVISIONING=true
                fi
                
                # ALBê°€ ì‹¤ì œë¡œ ì‘ë‹µí•˜ëŠ”ì§€ í™•ì¸
                if curl -s --connect-timeout 5 --max-time 10 -o /dev/null -w "%{http_code}" "http://$ALB_DNS${{ env.HEALTH_CHECK_PATH }}" | grep -E "^(200|404)$" >/dev/null; then
                  echo "âœ… ALB í”„ë¡œë¹„ì €ë‹ ì™„ë£Œ ë° ì—°ê²° ê°€ëŠ¥: $ALB_DNS"
                  echo "ALB_HOSTNAME=$ALB_DNS" >> $GITHUB_ENV
                  echo "DEPLOYMENT_METHOD=Ingress" >> $GITHUB_ENV
                  ALB_CREATED=true
                  break
                else
                  echo "â³ ALBëŠ” ìƒì„±ë˜ì—ˆì§€ë§Œ ì•„ì§ í”„ë¡œë¹„ì €ë‹ ì¤‘ì…ë‹ˆë‹¤... ($i/40)"
                fi
              else
                echo "â³ ALB ìƒì„± ëŒ€ê¸° ì¤‘... ($i/40)"
              fi
              
              # ì§„í–‰ ìƒí™© ìƒì„¸ í™•ì¸ (3ë²ˆë§ˆë‹¤)
              if [ $((i % 3)) -eq 0 ]; then
                echo "ğŸ” Ingress ìƒíƒœ í™•ì¸ (${i}/40)..."
                kubectl get ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }} || true
                
                # AWS Load Balancer Controller ìƒíƒœ í™•ì¸
                if [ $((i % 6)) -eq 0 ]; then
                  echo "ğŸ” AWS Load Balancer Controller Pod ìƒíƒœ:"
                  kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller || true
                  
                  # ìµœê·¼ ì´ë²¤íŠ¸ í™•ì¸
                  echo "ğŸ” ìµœê·¼ Ingress ì´ë²¤íŠ¸:"
                  kubectl describe ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }} | grep -A 10 "Events:" || true
                fi
              fi
              
              sleep 30
            done
            
            if [ "$ALB_CREATED" != "true" ]; then
              echo "âš ï¸ ALB ìƒì„±/í”„ë¡œë¹„ì €ë‹ ì‹œê°„ ì´ˆê³¼ (20ë¶„) - ìƒì„¸ ì§„ë‹¨ ì‹¤í–‰"
              
              # í˜„ì¬ ì‹œê°„ ë¡œê¹…
              echo "ğŸ• ì§„ë‹¨ ì‹œì‘ ì‹œê°„: $(date)"
              
              echo "ğŸ” ìµœì¢… Ingress ìƒíƒœ:"
              kubectl get ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }} -o yaml || true
              kubectl describe ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }} || true
              
              echo "ğŸ” Ingress finalizer ìƒíƒœ ì¬í™•ì¸:"
              final_finalizers=$(kubectl get ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }} -o jsonpath='{.metadata.finalizers}' 2>/dev/null || echo "NONE")
              echo "Finalizers: $final_finalizers"
              
              if [[ "$final_finalizers" == *"ingress.k8s.aws/resources"* ]]; then
                echo "âœ… Finalizerê°€ ì„¤ì •ë˜ì–´ ìˆìŒ - Controllerê°€ ì¸ì‹í–ˆìŒ"
              else
                echo "âŒ Finalizerê°€ ì—†ìŒ - Controllerê°€ Ingressë¥¼ ì²˜ë¦¬í•˜ì§€ ëª»í–ˆìŒ"
              fi
              
              echo "ğŸ” AWS Load Balancer Controller ìƒì„¸ ìƒíƒœ:"
              kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller -o wide || true
              kubectl describe pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller || true
              
              echo "ğŸ” AWS Load Balancer Controller ìµœê·¼ ë¡œê·¸ (ì‹¤íŒ¨ ê´€ë ¨):"
              kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --tail=200 | grep -i "error\|fail\|denied\|invalid\|timeout" || echo "ê´€ë ¨ ì—ëŸ¬ ë¡œê·¸ ì—†ìŒ"
              
              echo "ğŸ” AWS Load Balancer Controller ì „ì²´ ë¡œê·¸ (ìµœê·¼ 50ì¤„):"
              kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --tail=50 || true
              
              echo "ğŸ” IngressClass í™•ì¸:"
              kubectl get ingressclass || true
              kubectl describe ingressclass alb || true
              
              echo "ğŸ” ValidatingWebhookConfiguration í™•ì¸:"
              webhook_status=$(kubectl get validatingwebhookconfigurations | grep -E "(ingress|elb|load-balancer|aws)" || echo "ì›¹í›… ì—†ìŒ")
              echo "Webhook ìƒíƒœ: $webhook_status"
              
              if [[ "$webhook_status" == "ì›¹í›… ì—†ìŒ" ]]; then
                echo "âŒ ValidatingWebhookConfigurationì´ ì—†ìŠµë‹ˆë‹¤!"
                echo "ğŸ”§ ì´ëŠ” Ingress ìƒì„±ì´ ì°¨ë‹¨ë˜ì§€ ì•Šì•˜ì§€ë§Œ Controllerê°€ ì²˜ë¦¬í•˜ì§€ ëª»í–ˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤."
              else
                echo "âœ… ValidatingWebhookConfigurationì´ ìˆìŠµë‹ˆë‹¤."
              fi
              
              echo "ğŸ” ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ Ingress í™•ì¸:"
              kubectl get ingress -A || true
              
              echo "ğŸ” AWS CLIë¥¼ í†µí•œ ALB í™•ì¸:"
              aws elbv2 describe-load-balancers --query "LoadBalancers[?contains(LoadBalancerName, \`${{ env.PROJECT_NAME }}\`) || contains(LoadBalancerName, \`k8s\`)].{Name:LoadBalancerName,State:State.Code,DNS:DNSName}" --output table 2>/dev/null || echo "AWS CLIë¡œ ALB ì¡°íšŒ ì‹¤íŒ¨"
              
              # ALBê°€ ìƒì„±ë˜ì—ˆì§€ë§Œ í”„ë¡œë¹„ì €ë‹ì´ ì™„ë£Œë˜ì§€ ì•Šì€ ê²½ìš° í™˜ê²½ë³€ìˆ˜ ì„¤ì •
              if [ -n "$ALB_DNS" ] && [ "$ALB_DNS" != "null" ]; then
                echo "DEPLOYMENT_METHOD=Ingress-Provisioning" >> $GITHUB_ENV
                echo "ALB_HOSTNAME=$ALB_DNS" >> $GITHUB_ENV
                echo "â„¹ï¸ ALBê°€ ìƒì„±ë˜ì—ˆì§€ë§Œ í”„ë¡œë¹„ì €ë‹ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: $ALB_DNS"
                echo "â„¹ï¸ ìˆ˜ë™ìœ¼ë¡œ ALB ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
              else
                echo "DEPLOYMENT_METHOD=Ingress-Failed" >> $GITHUB_ENV
                echo "ALB_HOSTNAME=failed" >> $GITHUB_ENV
                echo "âŒ ALB ìƒì„± ìì²´ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
              fi
            fi
            
          else
            echo "âŒ Ingress ë°°í¬ ì‹¤íŒ¨"
            echo "ğŸ” ì§„ë‹¨ ì •ë³´:"
            kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller
            kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --tail=50 || true
            kubectl get validatingwebhookconfigurations | grep -E "(ingress|aws-load-balancer)" || echo "ì›¹í›… ì—†ìŒ"
            kubectl get ingressclass || true
            exit 1
          fi
          
          echo "âœ… Ingress ê¸°ë°˜ ALB ë°°í¬ ì™„ë£Œ"

          echo "â³ ë°°í¬ ì™„ë£Œ ëŒ€ê¸° ì¤‘..."
          echo "ğŸ” ë°°í¬ ì „ ìƒíƒœ í™•ì¸:"
          kubectl get pods -n ${{ env.PROJECT_NAME }} -o wide || true
          kubectl describe deployment ${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} || true
          
          # ë” ê¸´ timeoutìœ¼ë¡œ ë°°í¬ ëŒ€ê¸°
          if ! kubectl rollout status deployment/${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} --timeout=600s; then
            echo "âŒ ë°°í¬ timeout ë°œìƒ. ìƒì„¸ ì§„ë‹¨ ì‹œì‘..."
            
            echo "ğŸ” Pod ìƒíƒœ í™•ì¸:"
            kubectl get pods -n ${{ env.PROJECT_NAME }} -o wide
            
            echo "ğŸ” ì‹¤íŒ¨í•œ Pod ë¡œê·¸ í™•ì¸:"
            failed_pods=$(kubectl get pods -n ${{ env.PROJECT_NAME }} --field-selector=status.phase!=Running --no-headers -o custom-columns=":metadata.name" 2>/dev/null || echo "")
            if [ -n "$failed_pods" ]; then
              for pod in $failed_pods; do
                echo "=== Pod $pod ë¡œê·¸ ==="
                kubectl logs $pod -n ${{ env.PROJECT_NAME }} --tail=50 || true
                echo "=== Pod $pod ìƒì„¸ ì •ë³´ ==="
                kubectl describe pod $pod -n ${{ env.PROJECT_NAME }} || true
              done
            fi
            
            echo "ğŸ” Deployment ì´ë²¤íŠ¸ í™•ì¸:"
            kubectl describe deployment ${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }}
            
            echo "ğŸ” ConfigMap ë° Secret í™•ì¸:"
            kubectl get configmap -n ${{ env.PROJECT_NAME }} || true
            kubectl get secret -n ${{ env.PROJECT_NAME }} || true
            
            exit 1
          fi

      # ===============================================
      # ë°°í¬ ê²°ê³¼ í™•ì¸
      # ===============================================
    - name: Verify Deployment
      if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
      run: |
          echo "ğŸ” ë°°í¬ ìƒíƒœ í™•ì¸ ì¤‘..."
          echo "ë„¤ì„ìŠ¤í˜ì´ìŠ¤: ${{ env.PROJECT_NAME }}"
          echo "ì•± ë¼ë²¨: ${{ env.PROJECT_NAME }}-app"

          # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¡´ì¬ í™•ì¸
          if ! kubectl get namespace ${{ env.PROJECT_NAME }} >/dev/null 2>&1; then
            echo "âŒ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ '${{ env.PROJECT_NAME }}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            kubectl get namespaces
            exit 1
          fi

          # ê¸°ë³¸ ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸
          echo "ğŸ“‹ Pod ìƒíƒœ:"
          kubectl get pods -n ${{ env.PROJECT_NAME }} -o wide || echo "Podë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

          echo "ğŸ“‹ Service ìƒíƒœ:"
          kubectl get services -n ${{ env.PROJECT_NAME }} || echo "Serviceë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

          echo "ğŸ“‹ Deployment ìƒíƒœ:"
          kubectl get deployments -n ${{ env.PROJECT_NAME }} || echo "Deploymentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

          echo "ğŸ“‹ Ingress ìƒíƒœ:"
          kubectl get ingress -n ${{ env.PROJECT_NAME }} || echo "Ingressë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

          # Deployment ì¡´ì¬ í™•ì¸ í›„ ëŒ€ê¸°
          if kubectl get deployment ${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} >/dev/null 2>&1; then
            echo "â³ Pod ì¤€ë¹„ ìƒíƒœ ëŒ€ê¸° ì¤‘..."
            kubectl wait --for=condition=ready pod -l app=${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} --timeout=300s || echo "Pod ì¤€ë¹„ ìƒíƒœ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼"
            
            echo "ğŸ“ Deployment ìƒì„¸ ì •ë³´:"
            kubectl describe deployment ${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }}
            
          else
            echo "âŒ Deployment '${{ env.PROJECT_NAME }}-app'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            echo "ì‚¬ìš© ê°€ëŠ¥í•œ Deployment ëª©ë¡:"
            kubectl get deployments -n ${{ env.PROJECT_NAME }}
            exit 1
          fi

      # ===============================================
      # ë°°í¬ ë°©ë²•ë³„ ì ‘ì† URL ì œê³µ
      # ===============================================
    - name: Get Application URL
      if: success() && ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
      run: |
          echo "ğŸ”— ì• í”Œë¦¬ì¼€ì´ì…˜ ì ‘ì† ì •ë³´ í™•ì¸ ì¤‘..."
          echo "ë°°í¬ ë°©ë²•: ${DEPLOYMENT_METHOD:-Unknown}"

          if [ "${DEPLOYMENT_METHOD:-}" = "Ingress" ]; then
            echo "âœ… Ingress ALB ë°°í¬ ì™„ë£Œ!"
            echo "ğŸŒ ì• í”Œë¦¬ì¼€ì´ì…˜ ì ‘ì† URL: http://${ALB_HOSTNAME:-í™•ì¸ë¶ˆê°€}"
            
            # ì‹¤ì œ ì—°ê²° í…ŒìŠ¤íŠ¸
            echo "ğŸ” ALB ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
            if curl -s --connect-timeout 10 --max-time 15 -o /dev/null -w "%{http_code}" "http://${ALB_HOSTNAME}${{ env.HEALTH_CHECK_PATH }}" | grep -E "^(200|404)$" >/dev/null; then
              echo "âœ… ALB ì—°ê²° ì„±ê³µ - ì• í”Œë¦¬ì¼€ì´ì…˜ ì ‘ì† ê°€ëŠ¥"
            else
              echo "âš ï¸ ALB ì—°ê²° ì‹¤íŒ¨ - í—¬ìŠ¤ì²´í¬ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
              echo "ğŸ” íƒ€ê²Ÿ ê·¸ë£¹ í—¬ìŠ¤ ìƒíƒœ í™•ì¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            fi
            
            echo "ğŸ” Ingress ìƒíƒœ:"
            kubectl describe ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }}
            
          elif [ "${DEPLOYMENT_METHOD:-}" = "Ingress-Provisioning" ]; then
            echo "âš ï¸ ALBê°€ ìƒì„±ë˜ì—ˆì§€ë§Œ ì•„ì§ í”„ë¡œë¹„ì €ë‹ ì¤‘ì…ë‹ˆë‹¤"
            echo "ğŸŒ ALB DNS: http://${ALB_HOSTNAME:-í™•ì¸ë¶ˆê°€}"
            echo "â„¹ï¸ 5-10ë¶„ í›„ ì ‘ì†ì´ ê°€ëŠ¥í•  ì˜ˆì •ì…ë‹ˆë‹¤."
            
            echo "ğŸ” í˜„ì¬ ALB ì—°ê²° ìƒíƒœ:"
            curl -s --connect-timeout 5 --max-time 10 -w "HTTP ìƒíƒœì½”ë“œ: %{http_code}, ì‘ë‹µì‹œê°„: %{time_total}s\n" "http://${ALB_HOSTNAME}${{ env.HEALTH_CHECK_PATH }}" || echo "ì•„ì§ ì—°ê²° ë¶ˆê°€"
            
            echo "ğŸ” Ingress ìƒíƒœ:"
            kubectl describe ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }}
            
          elif [ "${DEPLOYMENT_METHOD:-}" = "Ingress-Failed" ]; then
            echo "âŒ ALB ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
            echo "ğŸ” í˜„ì¬ Ingress ìƒíƒœ:"
            kubectl get ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }}
            kubectl describe ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }}
            
            echo "ğŸ”§ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸:"
            echo "1. AWS Load Balancer Controllerê°€ ì •ìƒ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸"
            echo "2. IngressClass 'alb'ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"
            echo "3. AWS IAM ê¶Œí•œì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸"
            echo "4. ì„œë¸Œë„· íƒœê·¸ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸"
            
          elif [ "${DEPLOYMENT_METHOD:-}" = "Ingress-Pending" ]; then
            echo "âš ï¸ ALB ìƒì„±ì´ ì•„ì§ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            echo "ğŸ” í˜„ì¬ Ingress ìƒíƒœ:"
            kubectl get ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }}
            kubectl describe ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }}
            
            echo "ì ì‹œ í›„ ALBê°€ ìƒì„±ë˜ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ URLì„ í™•ì¸í•˜ì„¸ìš”:"
            echo "kubectl get ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }}"
            
          else
            echo "â“ ë°°í¬ ë°©ë²•ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            echo "ë°°í¬ ë°©ë²•: ${DEPLOYMENT_METHOD:-Unknown}"
            echo "ALB í˜¸ìŠ¤íŠ¸ëª…: ${ALB_HOSTNAME:-Unknown}"
            echo "ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ í™•ì¸:"
            kubectl get services -n ${{ env.PROJECT_NAME }}
            echo "ì‚¬ìš© ê°€ëŠ¥í•œ Ingress í™•ì¸:"
            kubectl get ingress -n ${{ env.PROJECT_NAME }}
          fi

          # ê³µí†µ ë””ë²„ê¹… ì •ë³´
          echo ""
          echo "ğŸ“‹ ì „ì²´ ë¦¬ì†ŒìŠ¤ ìƒíƒœ:"
          kubectl get all -n ${{ env.PROJECT_NAME }}

      # ===============================================
      # ë°°í¬ ì™„ë£Œ ì•Œë¦¼
      # ===============================================
    - name: Application Deployment Notification
      if: success() && ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' }}
      run: |
          echo "ğŸ‰ PHP ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ì™„ë£Œ!"
          echo "í”„ë¡œì íŠ¸: ${{ env.PROJECT_NAME }}"
          echo "ì´ë¯¸ì§€: ${{ steps.build-image.outputs.image }}"
          echo "í´ëŸ¬ìŠ¤í„°: ${{ env.EKS_CLUSTER_NAME }}"
          echo "ë„¤ì„ìŠ¤í˜ì´ìŠ¤: ${{ env.PROJECT_NAME }}"
          echo "ë°ì´í„°ë² ì´ìŠ¤: ${{ env.RDS_ENDPOINT }}"
          echo "ì»¤ë°‹: ${{ github.sha }}"
          echo "ë°°í¬ ì‹œê°„: $(date)"

          # ë°°í¬ëœ ì„œë¹„ìŠ¤ ì •ë³´ ì¶œë ¥
          echo "ğŸ“‹ ë°°í¬ëœ ë¦¬ì†ŒìŠ¤ ëª©ë¡:"
          kubectl get all -n ${{ env.PROJECT_NAME }} || echo "ë¦¬ì†ŒìŠ¤ ì¡°íšŒ ì‹¤íŒ¨"

      # ===============================================
      # ë°°í¬ ì‹¤íŒ¨ ì‹œ ë¡¤ë°± ë° ì •ë¦¬
      # ===============================================
    - name: Rollback on failure
      if: ${{ failure() && github.event_name == 'push' && github.ref == 'refs/heads/main' }}
      run: |
          echo "âŒ ë°°í¬ ì‹¤íŒ¨ - ë¡¤ë°± ë° ì •ë¦¬ ì‹œì‘..."
          
          # Ingress finalizer ì²´í¬ ë° ì •ë¦¬ í•¨ìˆ˜ ì¬ì •ì˜
          check_and_clean_ingress() {
            local namespace="$1"
            local ingress_name="$2"
            
            echo "ğŸ” ì‹¤íŒ¨í•œ Ingress '$ingress_name' (ë„¤ì„ìŠ¤í˜ì´ìŠ¤: $namespace) ì •ë¦¬ ì¤‘..."
            
            # Ingress ì¡´ì¬ í™•ì¸
            if ! kubectl get ingress "$ingress_name" -n "$namespace" >/dev/null 2>&1; then
              echo "â„¹ï¸ Ingress '$ingress_name'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
              return 0
            fi
            
            # finalizer í™•ì¸
            local finalizers=$(kubectl get ingress "$ingress_name" -n "$namespace" -o jsonpath='{.metadata.finalizers}' 2>/dev/null || echo "")
            
            if [[ "$finalizers" == *"ingress.k8s.aws/resources"* ]]; then
              echo "âš ï¸ Ingress '$ingress_name'ì— finalizerê°€ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤. ê°•ì œ ì •ë¦¬ ì‹œì‘..."
              
              # ìì‹ ì˜ ì•± ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë‚´ì˜ Ingressë§Œ ì •ìƒ ì‚­ì œ ì‹œë„
              echo "ğŸ—‘ï¸ ìê¸° ì•±ì˜ Ingressë§Œ ì •ìƒ ì‚­ì œ ì‹œë„..."
              kubectl delete ingress "$ingress_name" -n "$namespace" --timeout=30s || echo "Ingress ì‚­ì œ ì‹¤íŒ¨"
            else
              echo "âœ… Ingress '$ingress_name'ì— ë¬¸ì œë˜ëŠ” finalizer ì—†ìŒ"
              # ì •ìƒ ì‚­ì œ ì‹œë„
              kubectl delete ingress "$ingress_name" -n "$namespace" --timeout=30s || echo "Ingress ì‚­ì œ ì‹¤íŒ¨"
            fi
          }
          
          # ì‹¤íŒ¨í•œ Ingress ì •ë¦¬
          if kubectl get ingress -n ${{ env.PROJECT_NAME }} >/dev/null 2>&1; then
            echo "ğŸ—‘ï¸ ì‹¤íŒ¨í•œ Ingress ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘..."
            check_and_clean_ingress "${{ env.PROJECT_NAME }}" "${{ env.PROJECT_NAME }}-ingress"
          fi
          
          # ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡¤ë°±
          echo "ğŸ”„ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡¤ë°± ì¤‘..."
          kubectl rollout undo deployment/${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} || true
          kubectl rollout status deployment/${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} --timeout=300s || true
        
          echo "âœ… ë¡¤ë°± ë° ì •ë¦¬ ì™„ë£Œ"