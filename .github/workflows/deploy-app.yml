# .github/workflows/deploy-app.yml
# PHP ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ì›Œí¬í”Œë¡œìš° (server í´ë” ë³€ê²½ì‹œë§Œ ì‹¤í–‰)

name: Deploy PHP Application

on:
  push:
    branches: [main]
    paths:
      - "WALB/server/**"
  pull_request:
    branches: [main]
    paths:
      - "WALB/server/**"

env:
  PROJECT_NAME: "walb-app"

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    # ì›Œí‚¹ ë””ë ‰í† ë¦¬ë¥¼ WALBë¡œ ì„¤ì •
    defaults:
      run:
        working-directory: ./WALB

    permissions:
      id-token: write
      contents: read

    steps:
      # ===============================================
      # ì†ŒìŠ¤ì½”ë“œ ì²´í¬ì•„ì›ƒ
      # ===============================================
      - name: Checkout code
        uses: actions/checkout@v4

      # ===============================================
      # PHP ë° Composer í™˜ê²½ ì„¤ì •
      # ===============================================
      - name: Set up PHP
        uses: shivammathur/setup-php@v2
        with:
          php-version: "8.1"
          extensions: pdo, pdo_pgsql, mbstring, xml, zip, gd
          coverage: none

      - name: Validate Composer
        run: |
          echo "ğŸ” PHP ì• í”Œë¦¬ì¼€ì´ì…˜ ê²€ì¦ ì¤‘..."
          if [ -f "server/composer.json" ]; then
            cd server
            composer validate --no-check-publish
            composer install --no-dev --optimize-autoloader --no-interaction
            echo "âœ… Composer ê²€ì¦ ì™„ë£Œ"
          else
            echo "â„¹ï¸ Composer íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Docker ë¹Œë“œë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤."
          fi

      # ===============================================
      # AWS ì¸ì¦ (OIDC ë°©ì‹)
      # ===============================================
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN_APP }}
          aws-region: ${{ secrets.AWS_REGION }}
          role-session-name: GitHubActions-Application-${{ github.run_id }}

      # ===============================================
      # ê¸°ì¡´ ì¸í”„ë¼ ì •ë³´ ì¡°íšŒ
      # ===============================================
      - name: Get Infrastructure Resources
        run: |
          echo "ğŸ” ê¸°ì¡´ ì¸í”„ë¼ ë¦¬ì†ŒìŠ¤ ì •ë³´ ì¡°íšŒ ì¤‘..."

          # ECR ë¦¬í¬ì§€í† ë¦¬ URI ì¡°íšŒ
          ECR_REPO=$(aws ecr describe-repositories --repository-names ${PROJECT_NAME}-ecr --query 'repositories[0].repositoryUri' --output text 2>/dev/null || echo "")
          if [ -z "$ECR_REPO" ]; then
            echo "âŒ ECR ë¦¬í¬ì§€í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${PROJECT_NAME}-ecr"
            echo "ë¨¼ì € ì¸í”„ë¼ ë°°í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            exit 1
          fi
          echo "ECR_REPOSITORY=$ECR_REPO" >> $GITHUB_ENV
          echo "âœ… ECR Repository: $ECR_REPO"

          # EKS í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì¡°íšŒ
          EKS_CLUSTER=$(aws eks describe-cluster --name walb-eks-cluster --query 'cluster.name' --output text 2>/dev/null || echo "")
          if [ -z "$EKS_CLUSTER" ] || [ "$EKS_CLUSTER" == "None" ]; then
            echo "âŒ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${PROJECT_NAME}-eks"
            echo "ë¨¼ì € ì¸í”„ë¼ ë°°í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            exit 1
          fi
          echo "EKS_CLUSTER_NAME=$EKS_CLUSTER" >> $GITHUB_ENV
          echo "âœ… EKS Cluster: $EKS_CLUSTER"

          # RDS ì—”ë“œí¬ì¸íŠ¸ ì¡°íšŒ
          RDS_ENDPOINT=$(aws rds describe-db-instances --query 'DBInstances[?DBName==`mydb`].Endpoint.Address' --output text 2>/dev/null || echo "")
          if [ -z "$RDS_ENDPOINT" ] || [ "$RDS_ENDPOINT" == "None" ]; then
            echo "âŒ RDS ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            echo "ë¨¼ì € ì¸í”„ë¼ ë°°í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            exit 1
          fi
          echo "RDS_ENDPOINT=$RDS_ENDPOINT" >> $GITHUB_ENV
          echo "âœ… RDS Endpoint: $RDS_ENDPOINT"

          # EKS í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
          EKS_STATUS=$(aws eks describe-cluster --name $EKS_CLUSTER --query 'cluster.status' --output text)
          if [ "$EKS_STATUS" != "ACTIVE" ]; then
            echo "âŒ EKS í´ëŸ¬ìŠ¤í„°ê°€ í™œì„± ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤: $EKS_STATUS"
            exit 1
          fi
          echo "âœ… EKS Cluster Status: $EKS_STATUS"

      # ===============================================
      # ECR ë¡œê·¸ì¸
      # ===============================================
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      # ===============================================
      # Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ
      # ===============================================
      - name: Build and push Docker image
        id: build-image
        run: |
          echo "ğŸ³ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."

          # Git ì»¤ë°‹ í•´ì‹œë¥¼ íƒœê·¸ë¡œ ì‚¬ìš©
          IMAGE_TAG=${{ github.sha }}
          IMAGE_URI=${{ env.ECR_REPOSITORY }}:$IMAGE_TAG

          # server í´ë”ë¡œ ì´ë™í•´ì„œ Docker ë¹Œë“œ
          cd server
          docker build -t $IMAGE_URI .
          docker tag $IMAGE_URI ${{ env.ECR_REPOSITORY }}:latest

          echo "ğŸ“¤ ECRì— ì´ë¯¸ì§€ í‘¸ì‹œ ì¤‘..."
          docker push $IMAGE_URI
          docker push ${{ env.ECR_REPOSITORY }}:latest

          echo "âœ… ì´ë¯¸ì§€ í‘¸ì‹œ ì™„ë£Œ: $IMAGE_URI"
          echo "image=$IMAGE_URI" >> $GITHUB_OUTPUT

      - name: Database Connection and Schema Setup
        run: |
          # AWS CLIë¥¼ ì‚¬ìš©í•´ì„œ ë¦¬ì†ŒìŠ¤ ì •ë³´ ì§ì ‘ ì¡°íšŒ
          PROJECT_NAME="walb-app"

          # RDS ì—”ë“œí¬ì¸íŠ¸ ì¡°íšŒ (íƒœê·¸ ê¸°ë°˜)
          echo "ğŸ” RDS ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì¤‘..."
          DB_HOST=$(aws rds describe-db-instances \
            --query "DBInstances[?contains(keys(TagList[?Key=='Project']), 'Project') && TagList[?Key=='Project'].Value[0]=='${PROJECT_NAME}'].Endpoint.Address" \
            --output text 2>/dev/null || echo "")

          if [ -z "$DB_HOST" ]; then
            # íƒœê·¸ ì¡°íšŒê°€ ì•ˆ ë˜ë©´ DB ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ
            DB_HOST=$(aws rds describe-db-instances \
              --query "DBInstances[?DBName=='mydb'].Endpoint.Address" \
              --output text 2>/dev/null || echo "")
          fi

          # Bastion Host IP ì¡°íšŒ (íƒœê·¸ ê¸°ë°˜)
          echo "ğŸ” Bastion Host ì¡°íšŒ ì¤‘..."
          BASTION_IP=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=${PROJECT_NAME}-bastion-host" "Name=instance-state-name,Values=running" \
            --query "Reservations[0].Instances[0].PublicIpAddress" \
            --output text 2>/dev/null || echo "")

          if [ -z "$BASTION_IP" ] || [ "$BASTION_IP" == "None" ]; then
            # íƒœê·¸ë¡œ ì•ˆ ë˜ë©´ ë³´ì•ˆê·¸ë£¹ìœ¼ë¡œ ì¡°íšŒ
            BASTION_IP=$(aws ec2 describe-instances \
              --filters "Name=tag:Component,Values=Bastion" "Name=instance-state-name,Values=running" \
              --query "Reservations[0].Instances[0].PublicIpAddress" \
              --output text 2>/dev/null || echo "")
          fi

          # DB ì‚¬ìš©ìëª…ê³¼ DB ì´ë¦„ (í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©)
          DB_NAME="mydb"
          DB_USER="dbadmin"

          # Parameter Storeì—ì„œ DB íŒ¨ìŠ¤ì›Œë“œ ì¡°íšŒ
          echo "ğŸ” DB íŒ¨ìŠ¤ì›Œë“œ ì¡°íšŒ ì¤‘..."
          DB_PASSWORD=$(aws ssm get-parameter \
            --name "/${PROJECT_NAME}/rds/master-password" \
            --with-decryption \
            --query 'Parameter.Value' \
            --output text 2>/dev/null || echo "")

          # ê°’ ê²€ì¦
          if [ -z "$DB_HOST" ] || [ "$DB_HOST" == "None" ]; then
            echo "âŒ RDS ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            echo "ì‚¬ìš© ê°€ëŠ¥í•œ RDS ì¸ìŠ¤í„´ìŠ¤:"
            aws rds describe-db-instances --query "DBInstances[*].[DBInstanceIdentifier,Endpoint.Address,DBName]" --output table
            exit 1
          fi

          if [ -z "$BASTION_IP" ] || [ "$BASTION_IP" == "None" ]; then
            echo "âŒ Bastion Hostë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            echo "ì‹¤í–‰ ì¤‘ì¸ EC2 ì¸ìŠ¤í„´ìŠ¤:"
            aws ec2 describe-instances \
              --filters "Name=instance-state-name,Values=running" \
              --query "Reservations[*].Instances[*].[InstanceId,PublicIpAddress,Tags[?Key=='Name'].Value[0]]" \
              --output table
            exit 1
          fi

          if [ -z "$DB_PASSWORD" ]; then
            echo "âŒ DB íŒ¨ìŠ¤ì›Œë“œë¥¼ Parameter Storeì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            exit 1
          fi

          echo "âœ… DB Host: '$DB_HOST'"
          echo "âœ… Bastion IP: '$BASTION_IP'"
          echo "âœ… DB User: '$DB_USER'"
          echo "âœ… DB Name: '$DB_NAME'"

          # SSH í‚¤ë¥¼ Parameter Storeì—ì„œ ê°€ì ¸ì˜¤ê¸°
          echo "ğŸ”‘ SSH í‚¤ ì¡°íšŒ ì¤‘..."
          aws ssm get-parameter \
            --name "/${PROJECT_NAME}/bastion/ssh-private-key" \
            --with-decryption \
            --query 'Parameter.Value' \
            --output text > bastion_key.pem
          chmod 600 bastion_key.pem

          echo "ğŸ” SSH ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
          # SSH ì—°ê²° í…ŒìŠ¤íŠ¸ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
          if ! ssh -i bastion_key.pem -o StrictHostKeyChecking=no -o ConnectTimeout=10 -o BatchMode=yes ec2-user@$BASTION_IP "echo 'SSH connection successful'" 2>/dev/null; then
            echo "âŒ SSH ì—°ê²° ì‹¤íŒ¨. Bastion Host ìƒíƒœ í™•ì¸:"
            aws ec2 describe-instances \
              --filters "Name=tag:Component,Values=Bastion" \
              --query "Reservations[*].Instances[*].[InstanceId,State.Name,PublicIpAddress,PrivateIpAddress]" \
              --output table
            exit 1
          fi

          echo "ğŸ”— SSH í„°ë„ì„ í†µí•œ PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."

          # Bastion Hostì—ì„œ RDS ì—°ê²° í…ŒìŠ¤íŠ¸ ë¨¼ì € ìˆ˜í–‰
          echo "ğŸ” Bastion Hostì—ì„œ RDS ì§ì ‘ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
          echo "  DB Host: $DB_HOST"
          echo "  DB Port: 5432"

          # netcat ì„¤ì¹˜ ë° ì—°ê²° í…ŒìŠ¤íŠ¸
          ssh -i bastion_key.pem -o StrictHostKeyChecking=no -o ConnectTimeout=10 -o BatchMode=yes ec2-user@$BASTION_IP \
            "command -v nc >/dev/null 2>&1 || sudo yum install -y nc; echo 'Testing connection...'; timeout 10 nc -zv $DB_HOST 5432" || {
            echo "âš ï¸ Bastionì—ì„œ RDS ì§ì ‘ ì—°ê²° ì‹¤íŒ¨"
            echo "ëŒ€ì²´ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œë„ ì¤‘..."
            
            # telnet ëŒ€ì²´ í…ŒìŠ¤íŠ¸
            ssh -i bastion_key.pem -o StrictHostKeyChecking=no -o ConnectTimeout=10 -o BatchMode=yes ec2-user@$BASTION_IP \
              "timeout 10 bash -c 'exec 3<>/dev/tcp/$DB_HOST/5432' && echo 'Raw socket connection successful' || echo 'Raw socket connection failed'"
          }

          # ë³´ì•ˆ ê·¸ë£¹ ì •ë³´ í™•ì¸
          echo "ğŸ” ë³´ì•ˆ ê·¸ë£¹ ì •ë³´ í™•ì¸ ì¤‘..."
          BASTION_SG=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=${PROJECT_NAME}-bastion-host" "Name=instance-state-name,Values=running" \
            --query "Reservations[0].Instances[0].SecurityGroups[0].GroupId" --output text)

          RDS_SG=$(aws rds describe-db-instances \
            --query "DBInstances[?DBName=='mydb'].VpcSecurityGroups[0].VpcSecurityGroupId" --output text)

          echo "Bastion Security Group: $BASTION_SG"
          echo "RDS Security Group: $RDS_SG"

          # ë³´ì•ˆ ê·¸ë£¹ ê·œì¹™ í™•ì¸ (ê¶Œí•œì´ ìˆëŠ” ê²½ìš°ì—ë§Œ)
          if [ -n "$RDS_SG" ]; then
            echo "ğŸ” RDS ë³´ì•ˆ ê·¸ë£¹ ì¸ë°”ìš´ë“œ ê·œì¹™ í™•ì¸ ì‹œë„..."
            if aws ec2 describe-security-groups --group-ids "$RDS_SG" \
              --query "SecurityGroups[0].IpPermissions[?FromPort==\`5432\`]" --output table 2>/dev/null; then
              echo "âœ… ë³´ì•ˆ ê·¸ë£¹ ê·œì¹™ ì¡°íšŒ ì„±ê³µ"
            else
              echo "âš ï¸ ë³´ì•ˆ ê·¸ë£¹ ê·œì¹™ ì¡°íšŒ ê¶Œí•œ ì—†ìŒ (ì •ìƒ - ë³´ì•ˆìƒ ì œí•œ)"
              echo "RDS Security Group ID: $RDS_SG"
              echo "Bastion Security Group ID: $BASTION_SG"
            fi
          fi

          # SSH í„°ë„ì„ í†µí•œ PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸
          echo "ğŸ”— SSH í„°ë„ ìƒì„± ì¤‘..."
          ssh -i bastion_key.pem -o StrictHostKeyChecking=no -o ExitOnForwardFailure=yes -L 5432:$DB_HOST:5432 ec2-user@$BASTION_IP -N &
          SSH_PID=$!

          # í„°ë„ ì„¤ì • ëŒ€ê¸°
          sleep 15

          # PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ (í•„ìš”í•œ ê²½ìš°)
          if ! command -v psql &> /dev/null; then
            echo "ğŸ“¦ PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ ì¤‘..."
            sudo apt-get update && sudo apt-get install -y postgresql-client
          fi

          # ë¡œì»¬ í¬íŠ¸ë¥¼ í†µí•´ RDS ì—°ê²° í…ŒìŠ¤íŠ¸
          if PGPASSWORD=$DB_PASSWORD psql -h localhost -p 5432 -U $DB_USER -d $DB_NAME -c "SELECT 1;" 2>/dev/null; then
            echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ"
          else
            echo "âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"
            kill $SSH_PID 2>/dev/null
            rm -f bastion_key.pem
            exit 1
          fi

          # SSH í„°ë„ ì¢…ë£Œ ë° ì •ë¦¬
          kill $SSH_PID 2>/dev/null
          rm -f bastion_key.pem

          echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
        env:
          PROJECT_NAME: "walb-app"

      # ===============================================
      # PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ ë° ìŠ¤í‚¤ë§ˆ ì ìš©
      # ===============================================
      - name: Apply Database Schema
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          echo "ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì ìš© ì¤‘..."

          # PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜
          sudo apt-get update && sudo apt-get install -y postgresql-client

          # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
          PROJECT_NAME="walb-app"
          DB_HOST="${{ env.RDS_ENDPOINT }}"
          DB_NAME="mydb"
          DB_USER="dbadmin"

          # Bastion Host IP ì¡°íšŒ
          BASTION_IP=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=${PROJECT_NAME}-bastion-host" "Name=instance-state-name,Values=running" \
            --query "Reservations[0].Instances[0].PublicIpAddress" \
            --output text 2>/dev/null || echo "")

          if [ -z "$BASTION_IP" ] || [ "$BASTION_IP" == "None" ]; then
            echo "âŒ Bastion Hostë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            exit 1
          fi

          echo "ğŸ” ì—°ê²° ì •ë³´:"
          echo "  RDS ì—”ë“œí¬ì¸íŠ¸: $DB_HOST"
          echo "  Bastion IP: $BASTION_IP"
          echo "  DB ì´ë¦„: $DB_NAME"
          echo "  DB ì‚¬ìš©ì: $DB_USER"

          # SSH í‚¤ë¥¼ Parameter Storeì—ì„œ ê°€ì ¸ì˜¤ê¸°
          echo "ğŸ”‘ SSH í‚¤ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."
          aws ssm get-parameter \
            --name "/${PROJECT_NAME}/bastion/ssh-private-key" \
            --with-decryption \
            --query 'Parameter.Value' \
            --output text > bastion_key.pem
          chmod 600 bastion_key.pem

          # SSH í„°ë„ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
          echo "ğŸ”— SSH í„°ë„ ìƒì„± ì¤‘..."
          ssh -i bastion_key.pem \
              -o StrictHostKeyChecking=no \
              -o ExitOnForwardFailure=yes \
              -L 5432:$DB_HOST:5432 \
              ec2-user@$BASTION_IP \
              -N &
          SSH_PID=$!

          # í„°ë„ ì„¤ì • ëŒ€ê¸°
          echo "â³ SSH í„°ë„ ì„¤ì • ëŒ€ê¸° ì¤‘..."
          sleep 15

          # SSH í„°ë„ ìƒíƒœ í™•ì¸
          if ! kill -0 $SSH_PID 2>/dev/null; then
            echo "âŒ SSH í„°ë„ ìƒì„± ì‹¤íŒ¨"
            rm -f bastion_key.pem
            exit 1
          fi

          echo "âœ… SSH í„°ë„ ìƒì„± ì™„ë£Œ"

          # ë¡œì»¬ í¬íŠ¸ë¥¼ í†µí•´ RDS ì—°ê²° í…ŒìŠ¤íŠ¸
          echo "ğŸ” ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
          if ! PGPASSWORD="${{ secrets.DB_PASSWORD }}" psql \
            -h localhost \
            -p 5432 \
            -U "$DB_USER" \
            -d "$DB_NAME" \
            -c "SELECT version();" \
            -v ON_ERROR_STOP=1 >/dev/null 2>&1; then
            echo "âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"
            kill $SSH_PID 2>/dev/null
            rm -f bastion_key.pem
            exit 1
          fi

          echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ"

          # ê¸°ì¡´ í…Œì´ë¸” í™•ì¸
          echo "ğŸ” ê¸°ì¡´ í…Œì´ë¸” í™•ì¸ ì¤‘..."
          EXISTING_TABLES=$(PGPASSWORD="${{ secrets.DB_PASSWORD }}" psql \
            -h localhost \
            -p 5432 \
            -U "$DB_USER" \
            -d "$DB_NAME" \
            -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public' AND table_name IN ('users', 'posts', 'images', 'files');" \
            -v ON_ERROR_STOP=1 | tr -d ' ')

          if [ "$EXISTING_TABLES" -eq "0" ]; then
            echo "ğŸ“ ìŠ¤í‚¤ë§ˆ íŒŒì¼ ì ìš© ì¤‘..."
            if PGPASSWORD="${{ secrets.DB_PASSWORD }}" psql \
              -h localhost \
              -p 5432 \
              -U "$DB_USER" \
              -d "$DB_NAME" \
              -f server/files/schema.sql \
              -v ON_ERROR_STOP=1; then
              echo "âœ… ìŠ¤í‚¤ë§ˆ ì ìš© ì™„ë£Œ"
            else
              echo "âŒ ìŠ¤í‚¤ë§ˆ ì ìš© ì‹¤íŒ¨"
              kill $SSH_PID 2>/dev/null
              rm -f bastion_key.pem
              exit 1
            fi
          else
            echo "â„¹ï¸ í…Œì´ë¸”ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ìŠ¤í‚¤ë§ˆ ì ìš©ì„ ê±´ë„ˆëœë‹ˆë‹¤."
          fi

          # ì •ë¦¬ ì‘ì—…
          echo "ğŸ§¹ ì •ë¦¬ ì‘ì—… ì¤‘..."
          kill $SSH_PID 2>/dev/null
          rm -f bastion_key.pem

          echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì‘ì—… ì™„ë£Œ"

      # ===============================================
      # kubectl ë° Helm ì„¤ì¹˜
      # ===============================================
      - name: Install kubectl and Helm
        run: |
          echo "ğŸ”§ kubectl ë° Helm ì„¤ì¹˜ ì¤‘..."

          # kubectl ì„¤ì¹˜
          curl -LO "https://dl.k8s.io/release/v1.28.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

          # Helm ì„¤ì¹˜
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

          echo "âœ… kubectl ë° Helm ì„¤ì¹˜ ì™„ë£Œ"
          kubectl version --client
          helm version

      - name: Update kubeconfig for EKS
        run: |
          echo "ğŸ”§ EKS í´ëŸ¬ìŠ¤í„° kubeconfig ì—…ë°ì´íŠ¸ ì¤‘..."

          # í˜„ì¬ AWS ìê²© ì¦ëª… í™•ì¸
          echo "ğŸ” í˜„ì¬ AWS ìê²© ì¦ëª… í™•ì¸..."
          aws sts get-caller-identity

          # EKS í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì¡°íšŒ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
          echo "ğŸ” EKS í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì¤‘..."

          # ë°©ë²• 1: í´ëŸ¬ìŠ¤í„° ëª©ë¡ì—ì„œ ì²« ë²ˆì§¸ ì¡°íšŒ
          EKS_CLUSTER_NAME=$(aws eks list-clusters --query 'clusters[0]' --output text 2>/dev/null || echo "")

          # ë°©ë²• 2: íŠ¹ì • ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ
          if [ -z "$EKS_CLUSTER_NAME" ] || [ "$EKS_CLUSTER_NAME" == "None" ]; then
            EKS_CLUSTER_NAME="walb-eks-cluster"
            echo "ê¸°ë³¸ í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì‚¬ìš©: $EKS_CLUSTER_NAME"
          fi

          # í´ëŸ¬ìŠ¤í„° ì¡´ì¬ í™•ì¸
          if ! aws eks describe-cluster --name "$EKS_CLUSTER_NAME" --region ${{ secrets.AWS_REGION }} >/dev/null 2>&1; then
            echo "âŒ EKS í´ëŸ¬ìŠ¤í„° '$EKS_CLUSTER_NAME'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            echo "ì‚¬ìš© ê°€ëŠ¥í•œ í´ëŸ¬ìŠ¤í„° ëª©ë¡:"
            aws eks list-clusters --region ${{ secrets.AWS_REGION }}
            exit 1
          fi

          echo "âœ… EKS í´ëŸ¬ìŠ¤í„°: $EKS_CLUSTER_NAME"
          echo "EKS_CLUSTER_NAME=$EKS_CLUSTER_NAME" >> $GITHUB_ENV

          # í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
          CLUSTER_STATUS=$(aws eks describe-cluster --name "$EKS_CLUSTER_NAME" --region ${{ secrets.AWS_REGION }} --query 'cluster.status' --output text)
          echo "í´ëŸ¬ìŠ¤í„° ìƒíƒœ: $CLUSTER_STATUS"

          if [ "$CLUSTER_STATUS" != "ACTIVE" ]; then
            echo "âŒ í´ëŸ¬ìŠ¤í„°ê°€ ACTIVE ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤: $CLUSTER_STATUS"
            exit 1
          fi

          # kubeconfig ì—…ë°ì´íŠ¸ (ìƒì„¸ ë¡œê·¸ í¬í•¨)
          echo "ğŸ”§ kubeconfig ì—…ë°ì´íŠ¸ ì¤‘..."
          aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name "$EKS_CLUSTER_NAME" --verbose

          # í´ëŸ¬ìŠ¤í„° ì—°ê²° í…ŒìŠ¤íŠ¸ (ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ í¬í•¨)
          echo "ğŸ” í´ëŸ¬ìŠ¤í„° ì—°ê²° í…ŒìŠ¤íŠ¸..."
          if ! kubectl cluster-info --request-timeout=30s; then
            echo "âŒ kubectl cluster-info ì‹¤íŒ¨. ì¶”ê°€ ì§„ë‹¨ ì •ë³´:"
            
            # kubectl ì„¤ì • í™•ì¸
            echo "kubectl ì„¤ì • í™•ì¸:"
            kubectl config view
            
            # í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ í™•ì¸
            echo "í˜„ì¬ ì»¨í…ìŠ¤íŠ¸:"
            kubectl config current-context
            
            # í´ëŸ¬ìŠ¤í„° ì—”ë“œí¬ì¸íŠ¸ ì§ì ‘ í…ŒìŠ¤íŠ¸
            CLUSTER_ENDPOINT=$(aws eks describe-cluster --name "$EKS_CLUSTER_NAME" --region ${{ secrets.AWS_REGION }} --query 'cluster.endpoint' --output text)
            echo "í´ëŸ¬ìŠ¤í„° ì—”ë“œí¬ì¸íŠ¸: $CLUSTER_ENDPOINT"
            
            # IAM ì—­í• ê³¼ RBAC ë§¤í•‘ í™•ì¸
            echo "EKS í´ëŸ¬ìŠ¤í„°ì˜ aws-auth ConfigMap í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            exit 1
          fi

          echo "ğŸ” ë…¸ë“œ ìƒíƒœ í™•ì¸..."
          kubectl get nodes --show-labels

      # ===============================================
      # AWS Load Balancer Controller ì •ë¦¬ ë° ì¤€ë¹„
      # ===============================================
      - name: Clean up and prepare for AWS Load Balancer Controller
        run: |
          echo "ğŸ§¹ ê¸°ì¡´ AWS Load Balancer Controller ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘..."

          # ê¸°ì¡´ AWS Load Balancer Controller ì œê±°
          if helm list -n kube-system | grep -q aws-load-balancer-controller; then
            echo "ê¸°ì¡´ AWS Load Balancer Controller ì œê±° ì¤‘..."
            helm uninstall aws-load-balancer-controller -n kube-system || true
            sleep 10
          fi

          # ì›¹í›… ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
          kubectl delete validatingadmissionwebhook aws-load-balancer-webhook 2>/dev/null || echo "ValidatingAdmissionWebhook ì—†ìŒ"
          kubectl delete mutatingadmissionwebhook aws-load-balancer-webhook 2>/dev/null || echo "MutatingAdmissionWebhook ì—†ìŒ"
          kubectl delete service aws-load-balancer-webhook-service -n kube-system 2>/dev/null || echo "ì›¹í›… ì„œë¹„ìŠ¤ ì—†ìŒ"

          # cert-manager ì™„ì „ ì œê±° (ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
          echo "ğŸ—‘ï¸ cert-manager ì™„ì „ ì œê±° ì¤‘..."
          kubectl delete namespace cert-manager 2>/dev/null || true
          kubectl delete crd certificaterequests.cert-manager.io 2>/dev/null || true
          kubectl delete crd certificates.cert-manager.io 2>/dev/null || true
          kubectl delete crd challenges.acme.cert-manager.io 2>/dev/null || true
          kubectl delete crd clusterissuers.cert-manager.io 2>/dev/null || true
          kubectl delete crd issuers.cert-manager.io 2>/dev/null || true
          kubectl delete crd orders.acme.cert-manager.io 2>/dev/null || true
          helm uninstall cert-manager -n cert-manager 2>/dev/null || true
          
          echo "âœ… ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ"

      # ===============================================
      # AWS Load Balancer Controller ì„¤ì¹˜ (cert-manager ì—†ì´)
      # ===============================================
      - name: Install AWS Load Balancer Controller without cert-manager
        run: |
          echo "ğŸ”§ AWS Load Balancer Controller ì„¤ì¹˜ ì¤‘ (cert-manager ì—†ì´)..."

          # IAM Role í™•ì¸
          echo "ğŸ” IAM Role í™•ì¸ ì¤‘..."
          PRIMARY_ROLE_NAME="${{ env.EKS_CLUSTER_NAME }}-aws-load-balancer-controller"
          
          if aws iam get-role --role-name "$PRIMARY_ROLE_NAME" >/dev/null 2>&1; then
            IAM_ROLE_ARN="arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/$PRIMARY_ROLE_NAME"
            echo "âœ… IAM Role ë°œê²¬: $PRIMARY_ROLE_NAME"
          else
            # ë°±ì—… íŒ¨í„´ í™•ì¸
            BACKUP_PATTERNS=("walb-eks-cluster-aws-load-balancer-controller" "walb-app-aws-load-balancer-controller")
            FOUND_ROLE=""
            for ROLE_NAME in "${BACKUP_PATTERNS[@]}"; do
              if aws iam get-role --role-name "$ROLE_NAME" >/dev/null 2>&1; then
                IAM_ROLE_ARN="arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/$ROLE_NAME"
                FOUND_ROLE="$ROLE_NAME"
                echo "âœ… IAM Role ë°œê²¬: $ROLE_NAME"
                break
              fi
            done
            
            if [ -z "$FOUND_ROLE" ]; then
              echo "âŒ AWS Load Balancer Controller IAM Roleì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
              echo "ì˜ˆìƒ Role ì´ë¦„: $PRIMARY_ROLE_NAME"
              exit 1
            fi
          fi

          # VPC ID ì¡°íšŒ
          VPC_ID=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query "cluster.resourcesVpcConfig.vpcId" --output text)
          echo "VPC ID: $VPC_ID"

          # ServiceAccount ìƒì„±/ì—…ë°ì´íŠ¸
          echo "ğŸ”§ ServiceAccount ìƒì„± ì¤‘..."
          kubectl delete serviceaccount aws-load-balancer-controller -n kube-system 2>/dev/null || true
          kubectl apply -f - <<EOF
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: aws-load-balancer-controller
            namespace: kube-system
            annotations:
              eks.amazonaws.com/role-arn: $IAM_ROLE_ARN
          EOF

          # Helm repo ì¶”ê°€
          helm repo add eks https://aws.github.io/eks-charts
          helm repo update

          # ê¸°ì¡´ AWS Load Balancer Controller ì™„ì „ ì œê±°
          echo "ğŸ§¹ ê¸°ì¡´ AWS Load Balancer Controller ë° ì›¹í›… ì™„ì „ ì œê±° ì¤‘..."
          helm uninstall aws-load-balancer-controller -n kube-system 2>/dev/null || true
          
          # ëª¨ë“  ì›¹í›… ì œê±°
          kubectl delete validatingadmissionwebhook vingress.elbv2.k8s.aws 2>/dev/null || true
          kubectl delete validatingadmissionwebhook aws-load-balancer-webhook 2>/dev/null || true
          kubectl delete mutatingadmissionwebhook aws-load-balancer-webhook 2>/dev/null || true
          kubectl delete mutatingadmissionwebhook mingress.elbv2.k8s.aws 2>/dev/null || true
          
          # ì›¹í›… ì„œë¹„ìŠ¤ ì œê±°
          kubectl delete service aws-load-balancer-webhook-service -n kube-system 2>/dev/null || true
          
          echo "â³ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ëŒ€ê¸° (30ì´ˆ)..."
          sleep 30

          # AWS Load Balancer Controller ì„¤ì¹˜ (ì›¹í›… ì™„ì „ ë¹„í™œì„±í™” + ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ íšŒí”¼)
          echo "ğŸš€ AWS Load Balancer Controller ì„¤ì¹˜ (ì›¹í›… ì™„ì „ ë¹„í™œì„±í™”)..."
          
          # ìµœì‹  ì°¨íŠ¸ ë²„ì „ í™•ì¸ ë° ì„¤ì¹˜
          helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
            -n kube-system \
            --set clusterName=${{ env.EKS_CLUSTER_NAME }} \
            --set serviceAccount.create=false \
            --set serviceAccount.name=aws-load-balancer-controller \
            --set region=${{ secrets.AWS_REGION }} \
            --set vpcId=$VPC_ID \
            --set enableShield=false \
            --set enableWaf=false \
            --set enableWafv2=false \
            --set webhook.enabled=false \
            --set certManager.enabled=false \
            --set enableCertManager=false \
            --set webhook.certManager.enabled=false \
            --set ingressClass=alb \
            --set createIngressClassResource=true \
            --set replicaCount=1 \
            --set resources.limits.cpu=200m \
            --set resources.limits.memory=500Mi \
            --set resources.requests.cpu=100m \
            --set resources.requests.memory=200Mi \
            --set podDisruptionBudget.maxUnavailable=1 \
            --timeout=300s \
            --wait

          # Controller Pod ìƒíƒœ í™•ì¸
          echo "â³ AWS Load Balancer Controller Pod ì‹œì‘ ëŒ€ê¸° ì¤‘..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=aws-load-balancer-controller -n kube-system --timeout=300s

          # Controller ìƒíƒœ í™•ì¸ ë° ì›¹í›… ìƒíƒœ ëª¨ë‹ˆí„°ë§
          echo "ğŸ” AWS Load Balancer Controller ìƒíƒœ í™•ì¸ ì¤‘..."
          kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller
          
          # ì›¹í›… ìƒíƒœ í™•ì¸ ë° ì œê±° í™•ì¸
          echo "ğŸ” ì›¹í›… ìƒíƒœ í™•ì¸..."
          echo "ValidatingAdmissionWebhook ëª©ë¡:"
          kubectl get validatingadmissionwebhook | grep -E "(aws-load-balancer|elbv2)" || echo "âœ… AWS Load Balancer ê´€ë ¨ ì›¹í›… ì—†ìŒ"
          
          echo "MutatingAdmissionWebhook ëª©ë¡:"
          kubectl get mutatingadmissionwebhook | grep -E "(aws-load-balancer|elbv2)" || echo "âœ… AWS Load Balancer ê´€ë ¨ ì›¹í›… ì—†ìŒ"
          
          # Controller ë¡œê·¸ í™•ì¸
          echo "ğŸ” Controller ë¡œê·¸ í™•ì¸..."
          kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --tail=20 || true
          
          echo "âœ… AWS Load Balancer Controller ì¤€ë¹„ ì™„ë£Œ"

      # ===============================================
      # Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
      # ===============================================
      - name: Generate Kubernetes manifests
        run: |
          echo "ğŸ“ Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì¤‘..."

          # Namespace ìƒì„±
          cat <<EOF > namespace.yaml
          apiVersion: v1
          kind: Namespace
          metadata:
            name: ${{ env.PROJECT_NAME }}
            labels:
              name: ${{ env.PROJECT_NAME }}
          EOF

          # ConfigMap ìƒì„± (í™˜ê²½ë³€ìˆ˜)
          cat <<EOF > configmap.yaml
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: ${{ env.PROJECT_NAME }}-config
            namespace: ${{ env.PROJECT_NAME }}
          data:
            DB_HOST: "${{ env.RDS_ENDPOINT }}"
            DB_PORT: "5432"
            DB_NAME: "mydb"
            DB_USER: "dbadmin"
            AWS_REGION: "${{ secrets.AWS_REGION }}"
            AWS_S3_BUCKET: "walb-app-files"
            AWS_S3_REGION: "${{ secrets.AWS_REGION }}"
            STORAGE_TYPE: "s3"
            APP_ENV: "production"
            APP_DEBUG: "false"
            PHP_MEMORY_LIMIT: "256M"
            PHP_MAX_EXECUTION_TIME: "30"
            PHP_TIMEZONE: "Asia/Seoul"
            UPLOAD_MAX_SIZE: "10M"
            SESSION_LIFETIME: "7200"
          EOF

          # Secret ìƒì„± (DB íŒ¨ìŠ¤ì›Œë“œ)
          cat <<EOF > secret.yaml
          apiVersion: v1
          kind: Secret
          metadata:
            name: ${{ env.PROJECT_NAME }}-secret
            namespace: ${{ env.PROJECT_NAME }}
          type: Opaque
          data:
            DB_PASSWORD: $(echo -n "${{ secrets.DB_PASSWORD }}" | base64)
          EOF

          # Deployment ìƒì„±
          cat <<EOF > deployment.yaml
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: ${{ env.PROJECT_NAME }}-app
            namespace: ${{ env.PROJECT_NAME }}
            labels:
              app: ${{ env.PROJECT_NAME }}-app
          spec:
            replicas: 2
            selector:
              matchLabels:
                app: ${{ env.PROJECT_NAME }}-app
            template:
              metadata:
                labels:
                  app: ${{ env.PROJECT_NAME }}-app
              spec:
                serviceAccountName: ${{ env.PROJECT_NAME }}-service-account
                containers:
                - name: php-app
                  image: ${{ steps.build-image.outputs.image }}
                  ports:
                  - containerPort: 80
                    name: http
                  envFrom:
                  - configMapRef:
                      name: ${{ env.PROJECT_NAME }}-config
                  - secretRef:
                      name: ${{ env.PROJECT_NAME }}-secret
                  livenessProbe:
                    httpGet:
                      path: /healthcheck.php
                      port: 80
                    initialDelaySeconds: 60
                    periodSeconds: 30
                    timeoutSeconds: 10
                  readinessProbe:
                    httpGet:
                      path: /healthcheck.php
                      port: 80
                    initialDelaySeconds: 30
                    periodSeconds: 10
                    timeoutSeconds: 5
                  resources:
                    requests:
                      memory: "256Mi"
                      cpu: "250m"
                    limits:
                      memory: "512Mi"
                      cpu: "500m"
                  securityContext:
                    runAsNonRoot: false
                    allowPrivilegeEscalation: false
                    readOnlyRootFilesystem: false
          EOF

          # Service ìƒì„± (ClusterIPë¡œ ìœ ì§€ - Ingressê°€ ì‚¬ìš©)
          cat <<EOF > service.yaml
          apiVersion: v1
          kind: Service
          metadata:
            name: ${{ env.PROJECT_NAME }}-service
            namespace: ${{ env.PROJECT_NAME }}
            labels:
              app: ${{ env.PROJECT_NAME }}-app
          spec:
            type: ClusterIP
            ports:
            - port: 80
              targetPort: 80
              protocol: TCP
              name: http
            selector:
              app: ${{ env.PROJECT_NAME }}-app
          EOF

          # VPC ì„œë¸Œë„· ì •ë³´ ì¡°íšŒ
          echo "ğŸ” VPC ì„œë¸Œë„· ì •ë³´ ì¡°íšŒ ì¤‘..."
          PUBLIC_SUBNETS=$(aws ec2 describe-subnets \
            --filters "Name=vpc-id,Values=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query "cluster.resourcesVpcConfig.vpcId" --output text)" \
                      "Name=tag:Name,Values=*public*" \
            --query "Subnets[*].SubnetId" --output text | tr '\t' ',')

          if [ -z "$PUBLIC_SUBNETS" ]; then
            # íƒœê·¸ ê¸°ë°˜ ì¡°íšŒê°€ ì‹¤íŒ¨í•˜ë©´ EKS ì„œë¸Œë„· ì‚¬ìš©
            PUBLIC_SUBNETS=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query "cluster.resourcesVpcConfig.subnetIds" --output text | tr '\t' ',')
          fi

          echo "ì‚¬ìš©í•  ì„œë¸Œë„·: $PUBLIC_SUBNETS"

          # Service LoadBalancer ìƒì„± (Ingress ëŒ€ì•ˆ)
          cat <<EOF > service-loadbalancer.yaml
          apiVersion: v1
          kind: Service
          metadata:
            name: ${{ env.PROJECT_NAME }}-loadbalancer
            namespace: ${{ env.PROJECT_NAME }}
            annotations:
              # AWS Load Balancer ì„¤ì •
              service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
              service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"
              service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
              service.beta.kubernetes.io/aws-load-balancer-backend-protocol: "http"
              service.beta.kubernetes.io/aws-load-balancer-healthcheck-path: "/healthcheck.php"
              service.beta.kubernetes.io/aws-load-balancer-healthcheck-port: "80"
              service.beta.kubernetes.io/aws-load-balancer-healthcheck-protocol: "http"
              service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval: "30"
              service.beta.kubernetes.io/aws-load-balancer-healthcheck-timeout: "5"
              service.beta.kubernetes.io/aws-load-balancer-healthy-threshold: "2"
              service.beta.kubernetes.io/aws-load-balancer-unhealthy-threshold: "3"
              # íƒœê·¸ ì„¤ì •
              service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags: |
                Environment=${{ env.PROJECT_NAME }},Project=${{ env.PROJECT_NAME }},ManagedBy=Kubernetes
          spec:
            type: LoadBalancer
            ports:
            - port: 80
              targetPort: 80
              protocol: TCP
              name: http
            selector:
              app: ${{ env.PROJECT_NAME }}-app
          EOF

          # IngressClass ìƒì„± (ë°±ì—…ìš©)
          cat <<EOF > ingressclass.yaml
          apiVersion: networking.k8s.io/v1
          kind: IngressClass
          metadata:
            name: alb
            annotations:
              ingressclass.kubernetes.io/is-default-class: "true"
          spec:
            controller: ingress.k8s.aws/alb
          EOF

          # Ingress ìƒì„± (ì›¹í›… ìš°íšŒ ëª¨ë“œ - ë‹¨ìˆœí™”ëœ ì„¤ì •)
          cat <<EOF > ingress-simple.yaml
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: ${{ env.PROJECT_NAME }}-ingress-simple
            namespace: ${{ env.PROJECT_NAME }}
            annotations:
              # ìµœì†Œí•œì˜ ALB ì„¤ì •ìœ¼ë¡œ ì›¹í›… ì˜¤ë¥˜ ìµœì†Œí™”
              alb.ingress.kubernetes.io/scheme: internet-facing
              alb.ingress.kubernetes.io/target-type: ip
              alb.ingress.kubernetes.io/load-balancer-name: ${{ env.PROJECT_NAME }}-simple-alb
          spec:
            ingressClassName: alb
            rules:
            - http:
                paths:
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: ${{ env.PROJECT_NAME }}-service
                      port:
                        number: 80
          EOF

          # ServiceAccount ìƒì„± (IRSAìš©)
          cat <<EOF > serviceaccount.yaml
          apiVersion: v1
          kind: ServiceAccount
          metadata:
            name: ${{ env.PROJECT_NAME }}-service-account
            namespace: ${{ env.PROJECT_NAME }}
            annotations:
              eks.amazonaws.com/role-arn: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/walb-app-eks-app-role
          EOF

          echo "âœ… ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì™„ë£Œ"

      # ===============================================
      # EKSì— ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ (main ë¸Œëœì¹˜ì¼ ë•Œë§Œ)
      # ===============================================
      - name: Deploy to EKS
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          echo "ğŸš€ EKSì— ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ì¤‘..."

          # Namespace ë¨¼ì € ìƒì„±
          kubectl apply -f namespace.yaml

          # ë‚˜ë¨¸ì§€ ë¦¬ì†ŒìŠ¤ ë°°í¬
          kubectl apply -f serviceaccount.yaml
          kubectl apply -f configmap.yaml
          kubectl apply -f secret.yaml
          kubectl apply -f deployment.yaml
          kubectl apply -f service.yaml

          # 1ë‹¨ê³„: Service LoadBalancer ë°°í¬ (ìš°ì„  ì‹œë„)
          echo "ğŸ”— Service LoadBalancer ë°°í¬ ì¤‘ (Ingress ëŒ€ì•ˆ)..."
          if kubectl apply -f service-loadbalancer.yaml; then
            echo "âœ… Service LoadBalancer ë°°í¬ ì„±ê³µ"
            
            # LoadBalancer ì¤€ë¹„ ëŒ€ê¸°
            echo "â³ LoadBalancer ì¤€ë¹„ ëŒ€ê¸° ì¤‘..."
            for i in {1..12}; do
              LB_HOSTNAME=$(kubectl get service ${{ env.PROJECT_NAME }}-loadbalancer -n ${{ env.PROJECT_NAME }} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
              if [ -n "$LB_HOSTNAME" ]; then
                echo "âœ… LoadBalancer ì¤€ë¹„ ì™„ë£Œ: $LB_HOSTNAME"
                echo "LB_HOSTNAME=$LB_HOSTNAME" >> $GITHUB_ENV
                echo "DEPLOYMENT_METHOD=LoadBalancer" >> $GITHUB_ENV
                break
              fi
              echo "LoadBalancer ì¤€ë¹„ ëŒ€ê¸° ì¤‘... ($i/12)"
              sleep 15
            done
            
            if [ -z "$LB_HOSTNAME" ]; then
              echo "âš ï¸ LoadBalancer ì¤€ë¹„ ì‹œê°„ ì´ˆê³¼, Ingress ì‹œë„ë¡œ ì „í™˜..."
            else
              echo "âœ… Service LoadBalancer ë°°í¬ ì™„ë£Œ - Ingress ë‹¨ê³„ ê±´ë„ˆë›°ê¸°"
              echo "SKIP_INGRESS=true" >> $GITHUB_ENV
            fi
          else
            echo "âŒ Service LoadBalancer ë°°í¬ ì‹¤íŒ¨, Ingress ì‹œë„ë¡œ ì „í™˜..."
          fi
          
          # 2ë‹¨ê³„: LoadBalancer ì‹¤íŒ¨ ì‹œì—ë§Œ Ingress ì‹œë„
          if [ "${SKIP_INGRESS:-false}" != "true" ]; then
            echo "ğŸ”— Ingress ë°°í¬ ì‹œë„ (ë‹¨ìˆœí™”ëœ ì„¤ì •)..."
            
            # IngressClass ë°°í¬
            kubectl apply -f ingressclass.yaml || true
            sleep 5
            
            # ë‹¨ìˆœí™”ëœ Ingress ë°°í¬ (ì›¹í›… ìš°íšŒ)
            echo "ë‹¨ìˆœí™”ëœ Ingress ë°°í¬ ì‹œë„..."
            if kubectl apply -f ingress-simple.yaml --validate=false --force=true; then
              echo "âœ… ë‹¨ìˆœí™”ëœ Ingress ë°°í¬ ì„±ê³µ"
              
              # Ingress ìƒíƒœ í™•ì¸
              sleep 15
              if kubectl get ingress ${{ env.PROJECT_NAME }}-ingress-simple -n ${{ env.PROJECT_NAME }} >/dev/null 2>&1; then
                echo "âœ… Ingress ë¦¬ì†ŒìŠ¤ ìƒì„± í™•ì¸"
                kubectl describe ingress ${{ env.PROJECT_NAME }}-ingress-simple -n ${{ env.PROJECT_NAME }}
                echo "DEPLOYMENT_METHOD=Ingress" >> $GITHUB_ENV
              else
                echo "âŒ Ingress ë¦¬ì†ŒìŠ¤ ìƒì„± ì‹¤íŒ¨"
                echo "âš ï¸ LoadBalancerì™€ Ingress ëª¨ë‘ ì‹¤íŒ¨ - í¬íŠ¸í¬ì›Œë”©ìœ¼ë¡œ ëŒ€ì²´"
                echo "DEPLOYMENT_METHOD=PortForward" >> $GITHUB_ENV
              fi
            else
              echo "âŒ Ingress ë°°í¬ ì‹¤íŒ¨"
              echo "âš ï¸ LoadBalancerì™€ Ingress ëª¨ë‘ ì‹¤íŒ¨ - í¬íŠ¸í¬ì›Œë”©ìœ¼ë¡œ ëŒ€ì²´"
              echo "DEPLOYMENT_METHOD=PortForward" >> $GITHUB_ENV
              
              # ì§„ë‹¨ ì •ë³´ ìˆ˜ì§‘
              echo "ì§„ë‹¨ ì •ë³´:"
              kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller || true
              kubectl get validatingadmissionwebhook | grep -E "(vingress|aws-load-balancer)" || echo "ì›¹í›… ì—†ìŒ"
              kubectl get ingressclass || true
            fi
          fi

          echo "â³ ë°°í¬ ì™„ë£Œ ëŒ€ê¸° ì¤‘..."
          kubectl rollout status deployment/${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} --timeout=300s

      # ===============================================
      # ë°°í¬ ê²°ê³¼ í™•ì¸
      # ===============================================
      - name: Verify Deployment
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          echo "ğŸ” ë°°í¬ ìƒíƒœ í™•ì¸ ì¤‘..."
          echo "ë„¤ì„ìŠ¤í˜ì´ìŠ¤: ${{ env.PROJECT_NAME }}"
          echo "ì•± ë¼ë²¨: ${{ env.PROJECT_NAME }}-app"

          # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¡´ì¬ í™•ì¸
          if ! kubectl get namespace ${{ env.PROJECT_NAME }} >/dev/null 2>&1; then
            echo "âŒ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ '${{ env.PROJECT_NAME }}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            kubectl get namespaces
            exit 1
          fi

          # ê¸°ë³¸ ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸
          echo "ğŸ“‹ Pod ìƒíƒœ:"
          kubectl get pods -n ${{ env.PROJECT_NAME }} -o wide || echo "Podë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

          echo "ğŸ“‹ Service ìƒíƒœ:"
          kubectl get services -n ${{ env.PROJECT_NAME }} || echo "Serviceë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

          echo "ğŸ“‹ Deployment ìƒíƒœ:"
          kubectl get deployments -n ${{ env.PROJECT_NAME }} || echo "Deploymentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

          echo "ğŸ“‹ Ingress ìƒíƒœ:"
          kubectl get ingress -n ${{ env.PROJECT_NAME }} || echo "Ingressë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

          echo "ğŸ“‹ AWS Load Balancer Controller ìƒíƒœ:"
          kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller || echo "AWS Load Balancer Controllerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

          # Deployment ì¡´ì¬ í™•ì¸ í›„ ëŒ€ê¸°
          if kubectl get deployment ${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} >/dev/null 2>&1; then
            echo "â³ Pod ì¤€ë¹„ ìƒíƒœ ëŒ€ê¸° ì¤‘..."
            kubectl wait --for=condition=ready pod -l app=${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} --timeout=300s || echo "Pod ì¤€ë¹„ ìƒíƒœ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼"
            
            echo "ğŸ“ Deployment ìƒì„¸ ì •ë³´:"
            kubectl describe deployment ${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }}
            
          else
            echo "âŒ Deployment '${{ env.PROJECT_NAME }}-app'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            echo "ì‚¬ìš© ê°€ëŠ¥í•œ Deployment ëª©ë¡:"
            kubectl get deployments -n ${{ env.PROJECT_NAME }}
            exit 1
          fi

      # ===============================================
      # ë°°í¬ ë°©ë²•ë³„ ì ‘ì† URL ì œê³µ
      # ===============================================
      - name: Get Application URL
        if: success() && github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          echo "ğŸ”— ì• í”Œë¦¬ì¼€ì´ì…˜ ì ‘ì† ì •ë³´ í™•ì¸ ì¤‘..."
          echo "ë°°í¬ ë°©ë²•: ${DEPLOYMENT_METHOD:-Unknown}"

          if [ "${DEPLOYMENT_METHOD:-}" = "LoadBalancer" ]; then
            echo "ğŸŒ Service LoadBalancerë¡œ ë°°í¬ë¨"
            echo "ì• í”Œë¦¬ì¼€ì´ì…˜ ì ‘ì† URL: http://${LB_HOSTNAME:-í™•ì¸ë¶ˆê°€}"
            echo "ğŸ” LoadBalancer ì„œë¹„ìŠ¤ ìƒíƒœ:"
            kubectl describe service ${{ env.PROJECT_NAME }}-loadbalancer -n ${{ env.PROJECT_NAME }}
            
          elif [ "${DEPLOYMENT_METHOD:-}" = "Ingress" ]; then
            echo "ğŸ”— Ingressë¡œ ë°°í¬ë¨"
            # Ingressì—ì„œ ALB DNS í™•ì¸
            for i in {1..12}; do
              ALB_DNS=$(kubectl get ingress ${{ env.PROJECT_NAME }}-ingress-simple -n ${{ env.PROJECT_NAME }} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
              if [ -n "$ALB_DNS" ]; then
                echo "ğŸŒ ì• í”Œë¦¬ì¼€ì´ì…˜ ì ‘ì† URL: http://$ALB_DNS"
                break
              fi
              echo "ALB DNS ëŒ€ê¸° ì¤‘... ($i/12)"
              sleep 10
            done
            
            if [ -z "$ALB_DNS" ]; then
              echo "âš ï¸ ALB DNSë¥¼ ì•„ì§ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            fi
            
            echo "ğŸ” Ingress ìƒíƒœ:"
            kubectl describe ingress ${{ env.PROJECT_NAME }}-ingress-simple -n ${{ env.PROJECT_NAME }}
            
          elif [ "${DEPLOYMENT_METHOD:-}" = "PortForward" ]; then
            echo "âš ï¸ LoadBalancerì™€ Ingressê°€ ëª¨ë‘ ì‹¤íŒ¨í•˜ì—¬ í¬íŠ¸í¬ì›Œë”© ì‚¬ìš©"
            echo "ë¡œì»¬ ì ‘ê·¼ ë°©ë²•:"
            echo "kubectl port-forward -n ${{ env.PROJECT_NAME }} svc/${{ env.PROJECT_NAME }}-service 8080:80"
            echo "ê·¸ í›„ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8080 ì ‘ê·¼"
            
          else
            echo "â“ ë°°í¬ ë°©ë²•ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            echo "ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ í™•ì¸:"
            kubectl get services -n ${{ env.PROJECT_NAME }}
            echo "ì‚¬ìš© ê°€ëŠ¥í•œ Ingress í™•ì¸:"
            kubectl get ingress -n ${{ env.PROJECT_NAME }}
          fi

          # ê³µí†µ ë””ë²„ê¹… ì •ë³´
          echo ""
          echo "ğŸ“‹ ì „ì²´ ë¦¬ì†ŒìŠ¤ ìƒíƒœ:"
          kubectl get all -n ${{ env.PROJECT_NAME }}

      # ===============================================
      # ë°°í¬ ì™„ë£Œ ì•Œë¦¼
      # ===============================================
      - name: Application Deployment Notification
        if: success() && github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          echo "ğŸ‰ PHP ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ì™„ë£Œ!"
          echo "í”„ë¡œì íŠ¸: ${{ env.PROJECT_NAME }}"
          echo "ì´ë¯¸ì§€: ${{ steps.build-image.outputs.image }}"
          echo "í´ëŸ¬ìŠ¤í„°: ${{ env.EKS_CLUSTER_NAME }}"
          echo "ë„¤ì„ìŠ¤í˜ì´ìŠ¤: ${{ env.PROJECT_NAME }}"
          echo "ë°ì´í„°ë² ì´ìŠ¤: ${{ env.RDS_ENDPOINT }}"
          echo "ì»¤ë°‹: ${{ github.sha }}"
          echo "ë°°í¬ ì‹œê°„: $(date)"

          # ë°°í¬ëœ ì„œë¹„ìŠ¤ ì •ë³´ ì¶œë ¥
          echo "ğŸ“‹ ë°°í¬ëœ ë¦¬ì†ŒìŠ¤ ëª©ë¡:"
          kubectl get all -n ${{ env.PROJECT_NAME }} || echo "ë¦¬ì†ŒìŠ¤ ì¡°íšŒ ì‹¤íŒ¨"

      # ===============================================
      # ë°°í¬ ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
      # ===============================================
      - name: Rollback on failure
        if: failure() && github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          echo "âŒ ë°°í¬ ì‹¤íŒ¨ - ì´ì „ ë²„ì „ìœ¼ë¡œ ë¡¤ë°± ì¤‘..."
          kubectl rollout undo deployment/${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} || true
          kubectl rollout status deployment/${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} --timeout=300s || true
          echo "âœ… ë¡¤ë°± ì‹œë„ ì™„ë£Œ"
