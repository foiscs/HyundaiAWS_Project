# .github/workflows/deploy-app.yml
# PHP ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ì›Œí¬í”Œë¡œìš° (server í´ë” ë³€ê²½ì‹œë§Œ ì‹¤í–‰)

name: Deploy PHP Application

on:
  push:
    branches: [ main ]
    paths:
      - 'WALB/server/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'WALB/server/**'

env:
  PROJECT_NAME: "walb-app"
  
jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    # ì›Œí‚¹ ë””ë ‰í† ë¦¬ë¥¼ WALBë¡œ ì„¤ì •
    defaults:
      run:
        working-directory: ./WALB
    
    permissions:
      id-token: write
      contents: read
    
    steps:
    # ===============================================
    # ì†ŒìŠ¤ì½”ë“œ ì²´í¬ì•„ì›ƒ
    # ===============================================
    - name: Checkout code
      uses: actions/checkout@v4
    
    # ===============================================
    # PHP ë° Composer í™˜ê²½ ì„¤ì •
    # ===============================================
    - name: Set up PHP
      uses: shivammathur/setup-php@v2
      with:
        php-version: '8.1'
        extensions: pdo, pdo_pgsql, mbstring, xml, zip, gd
        coverage: none
    
    - name: Validate Composer
      run: |
        echo "ğŸ” PHP ì• í”Œë¦¬ì¼€ì´ì…˜ ê²€ì¦ ì¤‘..."
        if [ -f "server/composer.json" ]; then
          cd server
          composer validate --no-check-publish
          composer install --no-dev --optimize-autoloader --no-interaction
          echo "âœ… Composer ê²€ì¦ ì™„ë£Œ"
        else
          echo "â„¹ï¸ Composer íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Docker ë¹Œë“œë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤."
        fi
    
    # ===============================================
    # AWS ì¸ì¦ (OIDC ë°©ì‹)
    # ===============================================
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_ARN_APP }}
        aws-region: ${{ secrets.AWS_REGION }}
        role-session-name: GitHubActions-Application-${{ github.run_id }}

    # ===============================================
    # ê¸°ì¡´ ì¸í”„ë¼ ì •ë³´ ì¡°íšŒ
    # ===============================================
    - name: Get Infrastructure Resources
      run: |
        echo "ğŸ” ê¸°ì¡´ ì¸í”„ë¼ ë¦¬ì†ŒìŠ¤ ì •ë³´ ì¡°íšŒ ì¤‘..."
        
        # ECR ë¦¬í¬ì§€í† ë¦¬ URI ì¡°íšŒ
        ECR_REPO=$(aws ecr describe-repositories --repository-names ${PROJECT_NAME}-ecr --query 'repositories[0].repositoryUri' --output text 2>/dev/null || echo "")
        if [ -z "$ECR_REPO" ]; then
          echo "âŒ ECR ë¦¬í¬ì§€í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${PROJECT_NAME}-ecr"
          echo "ë¨¼ì € ì¸í”„ë¼ ë°°í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
          exit 1
        fi
        echo "ECR_REPOSITORY=$ECR_REPO" >> $GITHUB_ENV
        echo "âœ… ECR Repository: $ECR_REPO"
        
        # EKS í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì¡°íšŒ
        EKS_CLUSTER=$(aws eks describe-cluster --name walb-eks-cluster --query 'cluster.name' --output text 2>/dev/null || echo "")
        if [ -z "$EKS_CLUSTER" ] || [ "$EKS_CLUSTER" == "None" ]; then
          echo "âŒ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${PROJECT_NAME}-eks"
          echo "ë¨¼ì € ì¸í”„ë¼ ë°°í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
          exit 1
        fi
        echo "EKS_CLUSTER_NAME=$EKS_CLUSTER" >> $GITHUB_ENV
        echo "âœ… EKS Cluster: $EKS_CLUSTER"
        
        # RDS ì—”ë“œí¬ì¸íŠ¸ ì¡°íšŒ
        RDS_ENDPOINT=$(aws rds describe-db-instances --query 'DBInstances[?DBName==`mydb`].Endpoint.Address' --output text 2>/dev/null || echo "")
        if [ -z "$RDS_ENDPOINT" ] || [ "$RDS_ENDPOINT" == "None" ]; then
          echo "âŒ RDS ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
          echo "ë¨¼ì € ì¸í”„ë¼ ë°°í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤."
          exit 1
        fi
        echo "RDS_ENDPOINT=$RDS_ENDPOINT" >> $GITHUB_ENV
        echo "âœ… RDS Endpoint: $RDS_ENDPOINT"
        
        # EKS í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
        EKS_STATUS=$(aws eks describe-cluster --name $EKS_CLUSTER --query 'cluster.status' --output text)
        if [ "$EKS_STATUS" != "ACTIVE" ]; then
          echo "âŒ EKS í´ëŸ¬ìŠ¤í„°ê°€ í™œì„± ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤: $EKS_STATUS"
          exit 1
        fi
        echo "âœ… EKS Cluster Status: $EKS_STATUS"
    
    # ===============================================
    # ECR ë¡œê·¸ì¸
    # ===============================================
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
    
    # ===============================================
    # Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ
    # ===============================================
    - name: Build and push Docker image
      id: build-image
      run: |
        echo "ğŸ³ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."
        
        # Git ì»¤ë°‹ í•´ì‹œë¥¼ íƒœê·¸ë¡œ ì‚¬ìš©
        IMAGE_TAG=${{ github.sha }}
        IMAGE_URI=${{ env.ECR_REPOSITORY }}:$IMAGE_TAG
        
        # server í´ë”ë¡œ ì´ë™í•´ì„œ Docker ë¹Œë“œ
        cd server
        docker build -t $IMAGE_URI .
        docker tag $IMAGE_URI ${{ env.ECR_REPOSITORY }}:latest
        
        echo "ğŸ“¤ ECRì— ì´ë¯¸ì§€ í‘¸ì‹œ ì¤‘..."
        docker push $IMAGE_URI
        docker push ${{ env.ECR_REPOSITORY }}:latest
        
        echo "âœ… ì´ë¯¸ì§€ í‘¸ì‹œ ì™„ë£Œ: $IMAGE_URI"
        echo "image=$IMAGE_URI" >> $GITHUB_OUTPUT

    - name: Test Database Connection via Bastion
      run: |
        # AWS CLIë¥¼ ì‚¬ìš©í•´ì„œ ë¦¬ì†ŒìŠ¤ ì •ë³´ ì§ì ‘ ì¡°íšŒ
        PROJECT_NAME="walb-app"
        
        # RDS ì—”ë“œí¬ì¸íŠ¸ ì¡°íšŒ (íƒœê·¸ ê¸°ë°˜)
        echo "ğŸ” RDS ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ ì¤‘..."
        DB_HOST=$(aws rds describe-db-instances \
          --query "DBInstances[?contains(keys(TagList[?Key=='Project']), 'Project') && TagList[?Key=='Project'].Value[0]=='${PROJECT_NAME}'].Endpoint.Address" \
          --output text 2>/dev/null || echo "")
        
        if [ -z "$DB_HOST" ]; then
          # íƒœê·¸ ì¡°íšŒê°€ ì•ˆ ë˜ë©´ DB ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ
          DB_HOST=$(aws rds describe-db-instances \
            --query "DBInstances[?DBName=='mydb'].Endpoint.Address" \
            --output text 2>/dev/null || echo "")
        fi
        
        # Bastion Host IP ì¡°íšŒ (íƒœê·¸ ê¸°ë°˜)
        echo "ğŸ” Bastion Host ì¡°íšŒ ì¤‘..."
        BASTION_IP=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=${PROJECT_NAME}-bastion-host" "Name=instance-state-name,Values=running" \
          --query "Reservations[0].Instances[0].PublicIpAddress" \
          --output text 2>/dev/null || echo "")
        
        if [ -z "$BASTION_IP" ] || [ "$BASTION_IP" == "None" ]; then
          # íƒœê·¸ë¡œ ì•ˆ ë˜ë©´ ë³´ì•ˆê·¸ë£¹ìœ¼ë¡œ ì¡°íšŒ
          BASTION_IP=$(aws ec2 describe-instances \
            --filters "Name=tag:Component,Values=Bastion" "Name=instance-state-name,Values=running" \
            --query "Reservations[0].Instances[0].PublicIpAddress" \
            --output text 2>/dev/null || echo "")
        fi
        
        # DB ì‚¬ìš©ìëª…ê³¼ DB ì´ë¦„ (í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©)
        DB_NAME="mydb"
        DB_USER="dbadmin"
        
        # Parameter Storeì—ì„œ DB íŒ¨ìŠ¤ì›Œë“œ ì¡°íšŒ
        echo "ğŸ” DB íŒ¨ìŠ¤ì›Œë“œ ì¡°íšŒ ì¤‘..."
        DB_PASSWORD=$(aws ssm get-parameter \
          --name "/${PROJECT_NAME}/rds/master-password" \
          --with-decryption \
          --query 'Parameter.Value' \
          --output text 2>/dev/null || echo "")
        
        # ê°’ ê²€ì¦
        if [ -z "$DB_HOST" ] || [ "$DB_HOST" == "None" ]; then
          echo "âŒ RDS ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          echo "ì‚¬ìš© ê°€ëŠ¥í•œ RDS ì¸ìŠ¤í„´ìŠ¤:"
          aws rds describe-db-instances --query "DBInstances[*].[DBInstanceIdentifier,Endpoint.Address,DBName]" --output table
          exit 1
        fi
        
        if [ -z "$BASTION_IP" ] || [ "$BASTION_IP" == "None" ]; then
          echo "âŒ Bastion Hostë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          echo "ì‹¤í–‰ ì¤‘ì¸ EC2 ì¸ìŠ¤í„´ìŠ¤:"
          aws ec2 describe-instances \
            --filters "Name=instance-state-name,Values=running" \
            --query "Reservations[*].Instances[*].[InstanceId,PublicIpAddress,Tags[?Key=='Name'].Value[0]]" \
            --output table
          exit 1
        fi
        
        if [ -z "$DB_PASSWORD" ]; then
          echo "âŒ DB íŒ¨ìŠ¤ì›Œë“œë¥¼ Parameter Storeì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          exit 1
        fi
        
        echo "âœ… DB Host: '$DB_HOST'"
        echo "âœ… Bastion IP: '$BASTION_IP'"
        echo "âœ… DB User: '$DB_USER'"
        echo "âœ… DB Name: '$DB_NAME'"
        
        # SSH í‚¤ë¥¼ Parameter Storeì—ì„œ ê°€ì ¸ì˜¤ê¸°
        echo "ğŸ”‘ SSH í‚¤ ì¡°íšŒ ì¤‘..."
        aws ssm get-parameter \
          --name "/${PROJECT_NAME}/bastion/ssh-private-key" \
          --with-decryption \
          --query 'Parameter.Value' \
          --output text > bastion_key.pem
        chmod 600 bastion_key.pem
        
        echo "ğŸ” SSH ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
        # SSH ì—°ê²° í…ŒìŠ¤íŠ¸ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
        if ! ssh -i bastion_key.pem -o StrictHostKeyChecking=no -o ConnectTimeout=10 -o BatchMode=yes ec2-user@$BASTION_IP "echo 'SSH connection successful'" 2>/dev/null; then
          echo "âŒ SSH ì—°ê²° ì‹¤íŒ¨. Bastion Host ìƒíƒœ í™•ì¸:"
          aws ec2 describe-instances \
            --filters "Name=tag:Component,Values=Bastion" \
            --query "Reservations[*].Instances[*].[InstanceId,State.Name,PublicIpAddress,PrivateIpAddress]" \
            --output table
          exit 1
        fi
        
        echo "ğŸ”— SSH í„°ë„ì„ í†µí•œ PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
        
        # Bastion Hostì—ì„œ RDS ì—°ê²° í…ŒìŠ¤íŠ¸ ë¨¼ì € ìˆ˜í–‰
        echo "ğŸ” Bastion Hostì—ì„œ RDS ì§ì ‘ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
        echo "  DB Host: $DB_HOST"
        echo "  DB Port: 5432"
        
        # netcat ì„¤ì¹˜ ë° ì—°ê²° í…ŒìŠ¤íŠ¸
        ssh -i bastion_key.pem -o StrictHostKeyChecking=no -o ConnectTimeout=10 -o BatchMode=yes ec2-user@$BASTION_IP \
          "command -v nc >/dev/null 2>&1 || sudo yum install -y nc; echo 'Testing connection...'; timeout 10 nc -zv $DB_HOST 5432" || {
          echo "âš ï¸ Bastionì—ì„œ RDS ì§ì ‘ ì—°ê²° ì‹¤íŒ¨"
          echo "ëŒ€ì²´ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œë„ ì¤‘..."
          
          # telnet ëŒ€ì²´ í…ŒìŠ¤íŠ¸
          ssh -i bastion_key.pem -o StrictHostKeyChecking=no -o ConnectTimeout=10 -o BatchMode=yes ec2-user@$BASTION_IP \
            "timeout 10 bash -c 'exec 3<>/dev/tcp/$DB_HOST/5432' && echo 'Raw socket connection successful' || echo 'Raw socket connection failed'"
        }
        
        # ë³´ì•ˆ ê·¸ë£¹ ì •ë³´ í™•ì¸
        echo "ğŸ” ë³´ì•ˆ ê·¸ë£¹ ì •ë³´ í™•ì¸ ì¤‘..."
        BASTION_SG=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=${PROJECT_NAME}-bastion-host" "Name=instance-state-name,Values=running" \
          --query "Reservations[0].Instances[0].SecurityGroups[0].GroupId" --output text)
        
        RDS_SG=$(aws rds describe-db-instances \
          --query "DBInstances[?DBName=='mydb'].VpcSecurityGroups[0].VpcSecurityGroupId" --output text)
        
        echo "Bastion Security Group: $BASTION_SG"
        echo "RDS Security Group: $RDS_SG"
        
        # ë³´ì•ˆ ê·¸ë£¹ ê·œì¹™ í™•ì¸ (ê¶Œí•œì´ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        if [ -n "$RDS_SG" ]; then
          echo "ğŸ” RDS ë³´ì•ˆ ê·¸ë£¹ ì¸ë°”ìš´ë“œ ê·œì¹™ í™•ì¸ ì‹œë„..."
          if aws ec2 describe-security-groups --group-ids "$RDS_SG" \
            --query "SecurityGroups[0].IpPermissions[?FromPort==\`5432\`]" --output table 2>/dev/null; then
            echo "âœ… ë³´ì•ˆ ê·¸ë£¹ ê·œì¹™ ì¡°íšŒ ì„±ê³µ"
          else
            echo "âš ï¸ ë³´ì•ˆ ê·¸ë£¹ ê·œì¹™ ì¡°íšŒ ê¶Œí•œ ì—†ìŒ (ì •ìƒ - ë³´ì•ˆìƒ ì œí•œ)"
            echo "RDS Security Group ID: $RDS_SG"
            echo "Bastion Security Group ID: $BASTION_SG"
          fi
        fi
        
        # SSH í„°ë„ì„ í†µí•œ PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸
        echo "ğŸ”— SSH í„°ë„ ìƒì„± ì¤‘..."
        ssh -i bastion_key.pem -o StrictHostKeyChecking=no -o ExitOnForwardFailure=yes -L 5432:$DB_HOST:5432 ec2-user@$BASTION_IP -N &
        SSH_PID=$!
        
        # í„°ë„ ì„¤ì • ëŒ€ê¸°
        sleep 15
        
        # PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ (í•„ìš”í•œ ê²½ìš°)
        if ! command -v psql &> /dev/null; then
          echo "ğŸ“¦ PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ ì¤‘..."
          sudo apt-get update && sudo apt-get install -y postgresql-client
        fi
        
        # ë¡œì»¬ í¬íŠ¸ë¥¼ í†µí•´ RDS ì—°ê²° í…ŒìŠ¤íŠ¸
        if PGPASSWORD=$DB_PASSWORD psql -h localhost -p 5432 -U $DB_USER -d $DB_NAME -c "SELECT 1;" 2>/dev/null; then
          echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ"
        else
          echo "âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"
          kill $SSH_PID 2>/dev/null
          rm -f bastion_key.pem
          exit 1
        fi
        
        # SSH í„°ë„ ì¢…ë£Œ ë° ì •ë¦¬
        kill $SSH_PID 2>/dev/null
        rm -f bastion_key.pem
        
        echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
      env:
        PROJECT_NAME: "walb-app"
        
    # ===============================================
    # PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜ ë° ìŠ¤í‚¤ë§ˆ ì ìš©
    # ===============================================
    - name: Apply Database Schema
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        echo "ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì ìš© ì¤‘..."
        
        # PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì„¤ì¹˜
        sudo apt-get update && sudo apt-get install -y postgresql-client
        
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        PROJECT_NAME="walb-app"
        DB_HOST="${{ env.RDS_ENDPOINT }}"
        DB_NAME="mydb"
        DB_USER="dbadmin"
        
        # Bastion Host IP ì¡°íšŒ
        BASTION_IP=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=${PROJECT_NAME}-bastion-host" "Name=instance-state-name,Values=running" \
          --query "Reservations[0].Instances[0].PublicIpAddress" \
          --output text 2>/dev/null || echo "")
        
        if [ -z "$BASTION_IP" ] || [ "$BASTION_IP" == "None" ]; then
          echo "âŒ Bastion Hostë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          exit 1
        fi
        
        echo "ğŸ” ì—°ê²° ì •ë³´:"
        echo "  RDS ì—”ë“œí¬ì¸íŠ¸: $DB_HOST"
        echo "  Bastion IP: $BASTION_IP"
        echo "  DB ì´ë¦„: $DB_NAME"
        echo "  DB ì‚¬ìš©ì: $DB_USER"
        
        # SSH í‚¤ë¥¼ Parameter Storeì—ì„œ ê°€ì ¸ì˜¤ê¸°
        echo "ğŸ”‘ SSH í‚¤ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."
        aws ssm get-parameter \
          --name "/${PROJECT_NAME}/bastion/ssh-private-key" \
          --with-decryption \
          --query 'Parameter.Value' \
          --output text > bastion_key.pem
        chmod 600 bastion_key.pem
        
        # SSH í„°ë„ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰)
        echo "ğŸ”— SSH í„°ë„ ìƒì„± ì¤‘..."
        ssh -i bastion_key.pem \
            -o StrictHostKeyChecking=no \
            -o ExitOnForwardFailure=yes \
            -L 5432:$DB_HOST:5432 \
            ec2-user@$BASTION_IP \
            -N &
        SSH_PID=$!
        
        # í„°ë„ ì„¤ì • ëŒ€ê¸°
        echo "â³ SSH í„°ë„ ì„¤ì • ëŒ€ê¸° ì¤‘..."
        sleep 15
        
        # SSH í„°ë„ ìƒíƒœ í™•ì¸
        if ! kill -0 $SSH_PID 2>/dev/null; then
          echo "âŒ SSH í„°ë„ ìƒì„± ì‹¤íŒ¨"
          rm -f bastion_key.pem
          exit 1
        fi
        
        echo "âœ… SSH í„°ë„ ìƒì„± ì™„ë£Œ"
        
        # ë¡œì»¬ í¬íŠ¸ë¥¼ í†µí•´ RDS ì—°ê²° í…ŒìŠ¤íŠ¸
        echo "ğŸ” ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."
        if ! PGPASSWORD="${{ secrets.DB_PASSWORD }}" psql \
          -h localhost \
          -p 5432 \
          -U "$DB_USER" \
          -d "$DB_NAME" \
          -c "SELECT version();" \
          -v ON_ERROR_STOP=1 >/dev/null 2>&1; then
          echo "âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"
          kill $SSH_PID 2>/dev/null
          rm -f bastion_key.pem
          exit 1
        fi
        
        echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ"
        
        # ê¸°ì¡´ í…Œì´ë¸” í™•ì¸
        echo "ğŸ” ê¸°ì¡´ í…Œì´ë¸” í™•ì¸ ì¤‘..."
        EXISTING_TABLES=$(PGPASSWORD="${{ secrets.DB_PASSWORD }}" psql \
          -h localhost \
          -p 5432 \
          -U "$DB_USER" \
          -d "$DB_NAME" \
          -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public' AND table_name IN ('users', 'posts', 'images', 'files');" \
          -v ON_ERROR_STOP=1 | tr -d ' ')
        
        if [ "$EXISTING_TABLES" -eq "0" ]; then
          echo "ğŸ“ ìŠ¤í‚¤ë§ˆ íŒŒì¼ ì ìš© ì¤‘..."
          if PGPASSWORD="${{ secrets.DB_PASSWORD }}" psql \
            -h localhost \
            -p 5432 \
            -U "$DB_USER" \
            -d "$DB_NAME" \
            -f server/files/schema.sql \
            -v ON_ERROR_STOP=1; then
            echo "âœ… ìŠ¤í‚¤ë§ˆ ì ìš© ì™„ë£Œ"
          else
            echo "âŒ ìŠ¤í‚¤ë§ˆ ì ìš© ì‹¤íŒ¨"
            kill $SSH_PID 2>/dev/null
            rm -f bastion_key.pem
            exit 1
          fi
        else
          echo "â„¹ï¸ í…Œì´ë¸”ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ìŠ¤í‚¤ë§ˆ ì ìš©ì„ ê±´ë„ˆëœë‹ˆë‹¤."
        fi
        
        # ì •ë¦¬ ì‘ì—…
        echo "ğŸ§¹ ì •ë¦¬ ì‘ì—… ì¤‘..."
        kill $SSH_PID 2>/dev/null
        rm -f bastion_key.pem
        
        echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì‘ì—… ì™„ë£Œ"
    
    # ===============================================
    # kubectl ì„¤ì¹˜ ë° EKS ì—°ê²°
    # ===============================================
    - name: Install kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'
    
    - name: Update kubeconfig for EKS
      run: |
        echo "ğŸ”§ EKS í´ëŸ¬ìŠ¤í„° kubeconfig ì—…ë°ì´íŠ¸ ì¤‘..."
        
        # í˜„ì¬ AWS ìê²© ì¦ëª… í™•ì¸
        echo "ğŸ” í˜„ì¬ AWS ìê²© ì¦ëª… í™•ì¸..."
        aws sts get-caller-identity
        
        # EKS í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì¡°íšŒ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
        echo "ğŸ” EKS í´ëŸ¬ìŠ¤í„° ì¡°íšŒ ì¤‘..."
        
        # ë°©ë²• 1: í´ëŸ¬ìŠ¤í„° ëª©ë¡ì—ì„œ ì²« ë²ˆì§¸ ì¡°íšŒ
        EKS_CLUSTER_NAME=$(aws eks list-clusters --query 'clusters[0]' --output text 2>/dev/null || echo "")
        
        # ë°©ë²• 2: íŠ¹ì • ì´ë¦„ìœ¼ë¡œ ì¡°íšŒ
        if [ -z "$EKS_CLUSTER_NAME" ] || [ "$EKS_CLUSTER_NAME" == "None" ]; then
          EKS_CLUSTER_NAME="walb-eks-cluster"
          echo "ê¸°ë³¸ í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì‚¬ìš©: $EKS_CLUSTER_NAME"
        fi
        
        # í´ëŸ¬ìŠ¤í„° ì¡´ì¬ í™•ì¸
        if ! aws eks describe-cluster --name "$EKS_CLUSTER_NAME" --region ${{ secrets.AWS_REGION }} >/dev/null 2>&1; then
          echo "âŒ EKS í´ëŸ¬ìŠ¤í„° '$EKS_CLUSTER_NAME'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          echo "ì‚¬ìš© ê°€ëŠ¥í•œ í´ëŸ¬ìŠ¤í„° ëª©ë¡:"
          aws eks list-clusters --region ${{ secrets.AWS_REGION }}
          exit 1
        fi
        
        echo "âœ… EKS í´ëŸ¬ìŠ¤í„°: $EKS_CLUSTER_NAME"
        echo "EKS_CLUSTER_NAME=$EKS_CLUSTER_NAME" >> $GITHUB_ENV
        
        # í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
        CLUSTER_STATUS=$(aws eks describe-cluster --name "$EKS_CLUSTER_NAME" --region ${{ secrets.AWS_REGION }} --query 'cluster.status' --output text)
        echo "í´ëŸ¬ìŠ¤í„° ìƒíƒœ: $CLUSTER_STATUS"
        
        if [ "$CLUSTER_STATUS" != "ACTIVE" ]; then
          echo "âŒ í´ëŸ¬ìŠ¤í„°ê°€ ACTIVE ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤: $CLUSTER_STATUS"
          exit 1
        fi
        
        # kubeconfig ì—…ë°ì´íŠ¸ (ìƒì„¸ ë¡œê·¸ í¬í•¨)
        echo "ğŸ”§ kubeconfig ì—…ë°ì´íŠ¸ ì¤‘..."
        aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name "$EKS_CLUSTER_NAME" --verbose
        
        # kubeconfig íŒŒì¼ í™•ì¸
        echo "ğŸ“‹ kubeconfig íŒŒì¼ ë‚´ìš©:"
        cat ~/.kube/config
        
        # AWS CLI ë²„ì „ í™•ì¸
        echo "ğŸ” AWS CLI ë²„ì „:"
        aws --version
        
        # kubectl ë²„ì „ í™•ì¸
        echo "ğŸ” kubectl ë²„ì „:"
        kubectl version --client
        
        # í´ëŸ¬ìŠ¤í„° ì—°ê²° í…ŒìŠ¤íŠ¸ (ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ í¬í•¨)
        echo "ğŸ” í´ëŸ¬ìŠ¤í„° ì—°ê²° í…ŒìŠ¤íŠ¸..."
        if ! kubectl cluster-info --request-timeout=30s; then
          echo "âŒ kubectl cluster-info ì‹¤íŒ¨. ì¶”ê°€ ì§„ë‹¨ ì •ë³´:"
          
          # kubectl ì„¤ì • í™•ì¸
          echo "kubectl ì„¤ì • í™•ì¸:"
          kubectl config view
          
          # í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ í™•ì¸
          echo "í˜„ì¬ ì»¨í…ìŠ¤íŠ¸:"
          kubectl config current-context
          
          # í´ëŸ¬ìŠ¤í„° ì—”ë“œí¬ì¸íŠ¸ ì§ì ‘ í…ŒìŠ¤íŠ¸
          CLUSTER_ENDPOINT=$(aws eks describe-cluster --name "$EKS_CLUSTER_NAME" --region ${{ secrets.AWS_REGION }} --query 'cluster.endpoint' --output text)
          echo "í´ëŸ¬ìŠ¤í„° ì—”ë“œí¬ì¸íŠ¸: $CLUSTER_ENDPOINT"
          
          # IAM ì—­í• ê³¼ RBAC ë§¤í•‘ í™•ì¸
          echo "EKS í´ëŸ¬ìŠ¤í„°ì˜ aws-auth ConfigMap í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
          exit 1
        fi
        
        echo "ğŸ” ë…¸ë“œ ìƒíƒœ í™•ì¸..."
        kubectl get nodes --show-labels
    
    # ===============================================
    # AWS Load Balancer Controller ì„¤ì¹˜
    # ===============================================
    - name: Install AWS Load Balancer Controller
      run: |
        echo "ğŸ”§ AWS Load Balancer Controller ì„¤ì¹˜ ì¤‘..."
        
        # Helm ì„¤ì¹˜
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
        
        # AWS Load Balancer Controller ServiceAccount ìƒì„±
        kubectl apply -f - <<EOF
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          name: aws-load-balancer-controller
          namespace: kube-system
          annotations:
            eks.amazonaws.com/role-arn: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/${{ env.EKS_CLUSTER_NAME }}-aws-load-balancer-controller
        EOF
        
        # AWS Load Balancer Controller Helm chart ì„¤ì¹˜
        helm repo add eks https://aws.github.io/eks-charts
        helm repo update
        
        # ê¸°ì¡´ ì„¤ì¹˜ê°€ ìˆìœ¼ë©´ ì—…ê·¸ë ˆì´ë“œ, ì—†ìœ¼ë©´ ìƒˆë¡œ ì„¤ì¹˜
        if helm list -n kube-system | grep -q aws-load-balancer-controller; then
          echo "ê¸°ì¡´ AWS Load Balancer Controller ì—…ê·¸ë ˆì´ë“œ ì¤‘..."
          helm upgrade aws-load-balancer-controller eks/aws-load-balancer-controller \
            -n kube-system \
            --set clusterName=${{ env.EKS_CLUSTER_NAME }} \
            --set serviceAccount.create=false \
            --set serviceAccount.name=aws-load-balancer-controller \
            --set region=${{ secrets.AWS_REGION }} \
            --set vpcId=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query "cluster.resourcesVpcConfig.vpcId" --output text)
        else
          echo "ìƒˆë¡œìš´ AWS Load Balancer Controller ì„¤ì¹˜ ì¤‘..."
          helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
            -n kube-system \
            --set clusterName=${{ env.EKS_CLUSTER_NAME }} \
            --set serviceAccount.create=false \
            --set serviceAccount.name=aws-load-balancer-controller \
            --set region=${{ secrets.AWS_REGION }} \
            --set vpcId=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query "cluster.resourcesVpcConfig.vpcId" --output text)
        fi
        
        # Controller Pod ìƒíƒœ í™•ì¸
        echo "â³ AWS Load Balancer Controller Pod ì‹œì‘ ëŒ€ê¸° ì¤‘..."
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=aws-load-balancer-controller -n kube-system --timeout=300s
        
        echo "âœ… AWS Load Balancer Controller ì„¤ì¹˜ ì™„ë£Œ"
        kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller

    # ===============================================
    # Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    # ===============================================
    - name: Generate Kubernetes manifests
      run: |
        echo "ğŸ“ Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì¤‘..."
        
        # Namespace ìƒì„±
        cat <<EOF > namespace.yaml
        apiVersion: v1
        kind: Namespace
        metadata:
          name: ${{ env.PROJECT_NAME }}
          labels:
            name: ${{ env.PROJECT_NAME }}
        EOF
        
        # ConfigMap ìƒì„± (í™˜ê²½ë³€ìˆ˜)
        cat <<EOF > configmap.yaml
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: ${{ env.PROJECT_NAME }}-config
          namespace: ${{ env.PROJECT_NAME }}
        data:
          DB_HOST: "${{ env.RDS_ENDPOINT }}"
          DB_PORT: "5432"
          DB_NAME: "mydb"
          DB_USER: "dbadmin"
          AWS_REGION: "${{ secrets.AWS_REGION }}"
          AWS_S3_BUCKET: "walb-app-files"
          AWS_S3_REGION: "${{ secrets.AWS_REGION }}"
          STORAGE_TYPE: "s3"
          APP_ENV: "production"
          APP_DEBUG: "false"
          PHP_MEMORY_LIMIT: "256M"
          PHP_MAX_EXECUTION_TIME: "30"
          PHP_TIMEZONE: "Asia/Seoul"
          UPLOAD_MAX_SIZE: "10M"
          SESSION_LIFETIME: "7200"
        EOF
        
        # Secret ìƒì„± (DB íŒ¨ìŠ¤ì›Œë“œ)
        cat <<EOF > secret.yaml
        apiVersion: v1
        kind: Secret
        metadata:
          name: ${{ env.PROJECT_NAME }}-secret
          namespace: ${{ env.PROJECT_NAME }}
        type: Opaque
        data:
          DB_PASSWORD: $(echo -n "${{ secrets.DB_PASSWORD }}" | base64)
        EOF
        
        # Deployment ìƒì„±
        cat <<EOF > deployment.yaml
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: ${{ env.PROJECT_NAME }}-app
          namespace: ${{ env.PROJECT_NAME }}
          labels:
            app: ${{ env.PROJECT_NAME }}-app
        spec:
          replicas: 2
          selector:
            matchLabels:
              app: ${{ env.PROJECT_NAME }}-app
          template:
            metadata:
              labels:
                app: ${{ env.PROJECT_NAME }}-app
            spec:
              serviceAccountName: ${{ env.PROJECT_NAME }}-service-account
              containers:
              - name: php-app
                image: ${{ steps.build-image.outputs.image }}
                ports:
                - containerPort: 80
                  name: http
                envFrom:
                - configMapRef:
                    name: ${{ env.PROJECT_NAME }}-config
                - secretRef:
                    name: ${{ env.PROJECT_NAME }}-secret
                livenessProbe:
                  httpGet:
                    path: /healthcheck.php
                    port: 80
                  initialDelaySeconds: 60
                  periodSeconds: 30
                  timeoutSeconds: 10
                readinessProbe:
                  httpGet:
                    path: /healthcheck.php
                    port: 80
                  initialDelaySeconds: 30
                  periodSeconds: 10
                  timeoutSeconds: 5
                resources:
                  requests:
                    memory: "256Mi"
                    cpu: "250m"
                  limits:
                    memory: "512Mi"
                    cpu: "500m"
                securityContext:
                  runAsNonRoot: false
                  allowPrivilegeEscalation: false
                  readOnlyRootFilesystem: false
        EOF
        
        # Service ìƒì„± (ClusterIPë¡œ ìœ ì§€ - Ingressê°€ ì‚¬ìš©)
        cat <<EOF > service.yaml
        apiVersion: v1
        kind: Service
        metadata:
          name: ${{ env.PROJECT_NAME }}-service
          namespace: ${{ env.PROJECT_NAME }}
          labels:
            app: ${{ env.PROJECT_NAME }}-app
        spec:
          type: ClusterIP
          ports:
          - port: 80
            targetPort: 80
            protocol: TCP
            name: http
          selector:
            app: ${{ env.PROJECT_NAME }}-app
        EOF
        
        # Ingress ìƒì„± (AWS Load Balancer Controller ì‚¬ìš©)
        cat <<EOF > ingress.yaml
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        metadata:
          name: ${{ env.PROJECT_NAME }}-ingress
          namespace: ${{ env.PROJECT_NAME }}
          annotations:
            kubernetes.io/ingress.class: alb
            alb.ingress.kubernetes.io/scheme: internet-facing
            alb.ingress.kubernetes.io/target-type: ip
            alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80}]'
            alb.ingress.kubernetes.io/healthcheck-path: /healthcheck.php
            alb.ingress.kubernetes.io/healthcheck-interval-seconds: '30'
            alb.ingress.kubernetes.io/healthcheck-timeout-seconds: '5'
            alb.ingress.kubernetes.io/healthy-threshold-count: '2'
            alb.ingress.kubernetes.io/unhealthy-threshold-count: '2'
            alb.ingress.kubernetes.io/subnets: $(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query "cluster.resourcesVpcConfig.subnetIds" --output text | tr '\t' ',')
            alb.ingress.kubernetes.io/tags: Environment=${{ env.PROJECT_NAME }},Project=${{ env.PROJECT_NAME }}
        spec:
          ingressClassName: alb
          rules:
          - http:
              paths:
              - path: /
                pathType: Prefix
                backend:
                  service:
                    name: ${{ env.PROJECT_NAME }}-service
                    port:
                      number: 80
        EOF
        
        # ServiceAccount ìƒì„± (IRSAìš©)
        cat <<EOF > serviceaccount.yaml
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          name: ${{ env.PROJECT_NAME }}-service-account
          namespace: ${{ env.PROJECT_NAME }}
          annotations:
            eks.amazonaws.com/role-arn: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/walb-app-eks-app-role
        EOF
        
        echo "âœ… ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì™„ë£Œ"
    
    # ===============================================
    # EKSì— ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ (main ë¸Œëœì¹˜ì¼ ë•Œë§Œ)
    # ===============================================
    - name: Deploy to EKS
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        echo "ğŸš€ EKSì— ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ì¤‘..."
        
        # Namespace ë¨¼ì € ìƒì„±
        kubectl apply -f namespace.yaml
        
        # ë‚˜ë¨¸ì§€ ë¦¬ì†ŒìŠ¤ ë°°í¬
        kubectl apply -f serviceaccount.yaml
        kubectl apply -f configmap.yaml
        kubectl apply -f secret.yaml
        kubectl apply -f deployment.yaml
        kubectl apply -f service.yaml
        kubectl apply -f ingress.yaml
        
        echo "â³ ë°°í¬ ì™„ë£Œ ëŒ€ê¸° ì¤‘..."
        kubectl rollout status deployment/${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} --timeout=300s
    
    # ===============================================
    # ë°°í¬ ê²°ê³¼ í™•ì¸
    # ===============================================
    - name: Verify Deployment
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        echo "ğŸ” ë°°í¬ ìƒíƒœ í™•ì¸ ì¤‘..."
        echo "ë„¤ì„ìŠ¤í˜ì´ìŠ¤: ${{ env.PROJECT_NAME }}"
        echo "ì•± ë¼ë²¨: ${{ env.PROJECT_NAME }}-app"
        
        # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¡´ì¬ í™•ì¸
        if ! kubectl get namespace ${{ env.PROJECT_NAME }} >/dev/null 2>&1; then
          echo "âŒ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ '${{ env.PROJECT_NAME }}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
          kubectl get namespaces
          exit 1
        fi
        
        # ê¸°ë³¸ ë¦¬ì†ŒìŠ¤ ìƒíƒœ í™•ì¸
        echo "ğŸ“‹ Pod ìƒíƒœ:"
        kubectl get pods -n ${{ env.PROJECT_NAME }} -o wide || echo "Podë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        echo "ğŸ“‹ Service ìƒíƒœ:"
        kubectl get services -n ${{ env.PROJECT_NAME }} || echo "Serviceë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        echo "ğŸ“‹ Deployment ìƒíƒœ:"
        kubectl get deployments -n ${{ env.PROJECT_NAME }} || echo "Deploymentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        echo "ğŸ“‹ Ingress ìƒíƒœ:"
        kubectl get ingress -n ${{ env.PROJECT_NAME }} || echo "Ingressë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        echo "ğŸ“‹ AWS Load Balancer Controller ìƒíƒœ:"
        kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller || echo "AWS Load Balancer Controllerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # Deployment ì¡´ì¬ í™•ì¸ í›„ ëŒ€ê¸°
        if kubectl get deployment ${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} >/dev/null 2>&1; then
          echo "â³ Pod ì¤€ë¹„ ìƒíƒœ ëŒ€ê¸° ì¤‘..."
          kubectl wait --for=condition=ready pod -l app=${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} --timeout=300s || echo "Pod ì¤€ë¹„ ìƒíƒœ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼"
          
          echo "ğŸ“ Deployment ìƒì„¸ ì •ë³´:"
          kubectl describe deployment ${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }}
          
        else
          echo "âŒ Deployment '${{ env.PROJECT_NAME }}-app'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          echo "ì‚¬ìš© ê°€ëŠ¥í•œ Deployment ëª©ë¡:"
          kubectl get deployments -n ${{ env.PROJECT_NAME }}
          exit 1
        fi
    
    # ===============================================
    # LoadBalancer ì„¤ì • í™•ì¸ ë° ì ‘ì† URL ì œê³µ
    # ===============================================
    - name: Get Application URL
      if: success() && github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        echo "ğŸ”— ì• í”Œë¦¬ì¼€ì´ì…˜ ì ‘ì† ì •ë³´ í™•ì¸ ì¤‘..."
        
        # Ingressì—ì„œ ALB DNS í™•ì¸ (ìµœëŒ€ 5ë¶„ ëŒ€ê¸°)
        echo "â³ Ingress ALB ìƒì„± ëŒ€ê¸° ì¤‘..."
        for i in {1..30}; do
          ALB_DNS=$(kubectl get ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
          if [ -n "$ALB_DNS" ]; then
            echo "âœ… ALB DNS í™•ì¸: $ALB_DNS"
            break
          fi
          echo "ëŒ€ê¸° ì¤‘... ($i/30)"
          sleep 10
        done
        
        if [ -n "$ALB_DNS" ]; then
          echo "ğŸŒ ì• í”Œë¦¬ì¼€ì´ì…˜ ì ‘ì† URL: http://$ALB_DNS"
          echo "ğŸ” Ingress ìƒíƒœ:"
          kubectl describe ingress ${{ env.PROJECT_NAME }}-ingress -n ${{ env.PROJECT_NAME }}
        else
          echo "âš ï¸ Ingress ALB DNSë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
          echo "Ingress ìƒíƒœ í™•ì¸:"
          kubectl get ingress -n ${{ env.PROJECT_NAME }}
          echo "ëŒ€ì²´ ì ‘ê·¼ ë°©ë²•:"
          echo "kubectl port-forward -n ${{ env.PROJECT_NAME }} svc/${{ env.PROJECT_NAME }}-service 8080:80"
        fi
    
    # ===============================================
    # ë°°í¬ ì™„ë£Œ ì•Œë¦¼
    # ===============================================
    - name: Application Deployment Notification
      if: success() && github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        echo "ğŸ‰ PHP ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ì™„ë£Œ!"
        echo "í”„ë¡œì íŠ¸: ${{ env.PROJECT_NAME }}"
        echo "ì´ë¯¸ì§€: ${{ steps.build-image.outputs.image }}"
        echo "í´ëŸ¬ìŠ¤í„°: ${{ env.EKS_CLUSTER_NAME }}"
        echo "ë„¤ì„ìŠ¤í˜ì´ìŠ¤: ${{ env.PROJECT_NAME }}"
        echo "ë°ì´í„°ë² ì´ìŠ¤: ${{ env.RDS_ENDPOINT }}"
        echo "ì»¤ë°‹: ${{ github.sha }}"
        echo "ë°°í¬ ì‹œê°„: $(date)"
        
        # ë°°í¬ëœ ì„œë¹„ìŠ¤ ì •ë³´ ì¶œë ¥
        echo "ğŸ“‹ ë°°í¬ëœ ë¦¬ì†ŒìŠ¤ ëª©ë¡:"
        kubectl get all -n ${{ env.PROJECT_NAME }} || echo "ë¦¬ì†ŒìŠ¤ ì¡°íšŒ ì‹¤íŒ¨"

    # ===============================================
    # ë°°í¬ ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
    # ===============================================
    - name: Rollback on failure
      if: failure() && github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        echo "âŒ ë°°í¬ ì‹¤íŒ¨ - ì´ì „ ë²„ì „ìœ¼ë¡œ ë¡¤ë°± ì¤‘..."
        kubectl rollout undo deployment/${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} || true
        kubectl rollout status deployment/${{ env.PROJECT_NAME }}-app -n ${{ env.PROJECT_NAME }} --timeout=300s || true
        echo "âœ… ë¡¤ë°± ì‹œë„ ì™„ë£Œ"